{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930d59a7-ac35-48c7-9689-1cb227720649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model, layers\n",
    "from tensorflow.keras.layers import Input, Bidirectional, Dense, Conv1D, Conv3D, LSTM, Flatten, Attention, MultiHeadAttention, GlobalAveragePooling1D, Concatenate, Add, Dropout, Softmax\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from utilz import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97b64b56-957e-4d30-9e14-7ae2446c3e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-18 12:29:41.979937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 12:29:42.009939: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 12:29:42.010051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78d78998-d3cb-4f21-9f9e-45ccf1fbb3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_clip = load_features('./data/visual_clip.pkl')\n",
    "acoustic = load_features('./data/acoustic_wav2vec.pkl')\n",
    "bert_embs = load_features('./data/textual_bert.pkl')\n",
    "label = load_features('./data/labels.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5184f46f-ae68-457b-952a-dc51de7c1db1",
   "metadata": {},
   "source": [
    "# From scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af3a756-8b76-4b53-b2f0-c95935a528bc",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a686fd9d-c8b5-4ab6-a77c-072887b133da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_Self(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(Attention_Self, self).__init__(**kwargs)\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.S = tf.keras.layers.Dense(1)\n",
    "        self.units = units\n",
    "\n",
    "    def call(self, features):\n",
    "        features_ = tf.expand_dims(features, 1)\n",
    "        v = self.W1(features)\n",
    "        q =  self.W2(features_)\n",
    "        score = tf.nn.tanh(q + v)\n",
    "        attention_weights = tf.nn.softmax(self.S(score), axis=1)\n",
    "        ATTN = attention_weights * (v)\n",
    "        ATTN = tf.reduce_sum(ATTN, axis=1)\n",
    "        \n",
    "        return ATTN\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(Attention_Self, self).get_config()\n",
    "        config.update({\"units\": self.units})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb69f497-2d71-43e0-ac18-0f2ee04240d4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 22:11:51.359712: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 22:11:51.380725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 22:11:51.380833: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 22:11:51.381670: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-12 22:11:51.383150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 22:11:51.383277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 22:11:51.383347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 22:11:51.704207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 22:11:51.704358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 22:11:51.704433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 22:11:51.704505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14217 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 10, 512)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 10, 64)       98368       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 128, 512)]   0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 36, 768)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 10, 64)       4160        ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 63, 64)       98368       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 34, 64)       147520      ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 34, 64)       147520      ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 10, 64)       12352       ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " attention__self (Attention_Sel  (None, 63, 32)      4193        ['conv1d_3[0][0]']               \n",
      " f)                                                                                               \n",
      "                                                                                                  \n",
      " attention (Attention)          (None, 34, 64)       0           ['conv1d_4[0][0]',               \n",
      "                                                                  'conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 64)           33024       ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 64)           16640       ['attention__self[0][0]']        \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 64)          0           ['conv1d_4[0][0]']               \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 64)          0           ['attention[0][0]']              \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 256)          0           ['lstm[0][0]',                   \n",
      "                                                                  'bidirectional[0][0]',          \n",
      "                                                                  'global_average_pooling1d[0][0]'\n",
      "                                                                 , 'global_average_pooling1d_1[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 64)           16448       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 3)            195         ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 578,788\n",
      "Trainable params: 578,788\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# './res/V_model_CNNLSTM_clip.tf'\n",
    "vis_ipt = Input((10, 512))\n",
    "vis_h = Conv1D(64, 3, 1, 'same')(vis_ipt)\n",
    "vis_h = Conv1D(64, 1, 1, 'same')(vis_h)\n",
    "vis_h = Conv1D(64, 3, 1, 'same')(vis_h)\n",
    "vis_h = LSTM(64, activation='relu')(vis_h)\n",
    "\n",
    "# './res/A_model_Att-BLSTM_wav2vec_v2.tf'\n",
    "aud_ipt = Input((128,512))\n",
    "aud_h = Conv1D(64, 3, 2)(aud_ipt)\n",
    "aud_h = Attention_Self(32)(aud_h)\n",
    "aud_h = Bidirectional(LSTM(32))(aud_h)\n",
    "\n",
    "# './res/T_model_AttCNN_bert.tf'\n",
    "tex_ipt = Input((36,768))\n",
    "tex_q = Conv1D(64, 3, 1)(tex_ipt)\n",
    "tex_v = Conv1D(64, 3, 1)(tex_ipt)\n",
    "tex_qv_attention = Attention()([tex_q, tex_v])\n",
    "tex_q = GlobalAveragePooling1D()(tex_q)\n",
    "tex_qv_attention = GlobalAveragePooling1D()(tex_qv_attention)\n",
    "# h = Concatenate()([q, qv_attention])\n",
    "\n",
    "h = Concatenate()([vis_h, aud_h, tex_q, tex_qv_attention])\n",
    "h = Dense(64)(h)\n",
    "res = Dense(3, activation='softmax')(h)\n",
    "\n",
    "model = Model(inputs=[vis_ipt, aud_ipt, tex_ipt], outputs=res)\n",
    "model.compile(optimizer='Adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics='acc')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97ca5a41-3765-4c35-a837-01e6c5eab6a9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 13:35:26.290913: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8500\n",
      "2022-10-12 13:35:26.634847: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/86 [============================>.] - ETA: 0s - loss: 0.9914 - acc: 0.5588"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_concate.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_concate.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 12s 103ms/step - loss: 0.9906 - acc: 0.5592 - val_loss: 0.9178 - val_acc: 0.6009\n",
      "Epoch 2/30\n",
      "86/86 [==============================] - 2s 21ms/step - loss: 0.7794 - acc: 0.6827 - val_loss: 0.9408 - val_acc: 0.6360\n",
      "Epoch 3/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.6120 - acc: 0.7471 - val_loss: 1.0456 - val_acc: 0.5833\n",
      "Epoch 4/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.5927 - acc: 0.7690 - val_loss: 1.0651 - val_acc: 0.6206\n",
      "Epoch 5/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.4239 - acc: 0.8268 - val_loss: 1.2184 - val_acc: 0.6316\n",
      "Epoch 6/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.3380 - acc: 0.8728 - val_loss: 1.4028 - val_acc: 0.5811\n",
      "Epoch 7/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.3561 - acc: 0.8596 - val_loss: 1.7769 - val_acc: 0.6075\n",
      "Epoch 8/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.3033 - acc: 0.8874 - val_loss: 1.7682 - val_acc: 0.6009\n",
      "Epoch 9/30\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.3007 - acc: 0.8925 - val_loss: 1.8019 - val_acc: 0.6250\n",
      "Epoch 10/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.2109 - acc: 0.9313 - val_loss: 2.0533 - val_acc: 0.5461\n",
      "Epoch 11/30\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.1458 - acc: 0.9423 - val_loss: 2.2673 - val_acc: 0.5504\n",
      "Epoch 12/30\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.0757 - acc: 0.9744 - val_loss: 2.4352 - val_acc: 0.5789\n",
      "Epoch 13/30\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.0347 - acc: 0.9912 - val_loss: 2.7277 - val_acc: 0.5833\n",
      "Epoch 14/30\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.0259 - acc: 0.9927 - val_loss: 2.8638 - val_acc: 0.5899\n",
      "Epoch 15/30\n",
      "86/86 [==============================] - 2s 26ms/step - loss: 0.0075 - acc: 0.9993 - val_loss: 2.9558 - val_acc: 0.5965\n",
      "Epoch 16/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 3.1327 - val_acc: 0.6009\n",
      "Epoch 17/30\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 3.1917 - val_acc: 0.5943\n",
      "Epoch 18/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 9.3197e-04 - acc: 1.0000 - val_loss: 3.2812 - val_acc: 0.6031\n",
      "Epoch 19/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 7.1438e-04 - acc: 1.0000 - val_loss: 3.3269 - val_acc: 0.5943\n",
      "Epoch 20/30\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 5.9261e-04 - acc: 1.0000 - val_loss: 3.3737 - val_acc: 0.5899\n",
      "Epoch 21/30\n",
      "86/86 [==============================] - 2s 18ms/step - loss: 4.9363e-04 - acc: 1.0000 - val_loss: 3.4167 - val_acc: 0.5921\n",
      "Epoch 22/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 4.1895e-04 - acc: 1.0000 - val_loss: 3.4638 - val_acc: 0.5943\n",
      "Epoch 23/30\n",
      "86/86 [==============================] - 2s 19ms/step - loss: 3.9383e-04 - acc: 1.0000 - val_loss: 3.4830 - val_acc: 0.5943\n",
      "Epoch 24/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 3.4067e-04 - acc: 1.0000 - val_loss: 3.5252 - val_acc: 0.5943\n",
      "Epoch 25/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 2.9367e-04 - acc: 1.0000 - val_loss: 3.5662 - val_acc: 0.5965\n",
      "Epoch 26/30\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 2.6967e-04 - acc: 1.0000 - val_loss: 3.5933 - val_acc: 0.5987\n",
      "Epoch 27/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 2.3528e-04 - acc: 1.0000 - val_loss: 3.6241 - val_acc: 0.5965\n",
      "Epoch 28/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 2.0901e-04 - acc: 1.0000 - val_loss: 3.6599 - val_acc: 0.6009\n",
      "Epoch 29/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 1.9668e-04 - acc: 1.0000 - val_loss: 3.6889 - val_acc: 0.5965\n",
      "Epoch 30/30\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 1.7515e-04 - acc: 1.0000 - val_loss: 3.7068 - val_acc: 0.5943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feb34f05120>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_list = [ModelCheckpoint(filepath='./res/multi_model_concate.tf', monitor='val_loss', save_best_only=True, save_freq='epoch')]\n",
    "\n",
    "model.fit(x=[np.asarray(visual_clip['train']), np.asarray(acoustic['train']), np.asarray(bert_embs['train'])], y=np.asarray(label['train']), batch_size=16, epochs=30, \n",
    "            validation_data=[[np.asarray(visual_clip['valid']), np.asarray(acoustic['valid']), np.asarray(bert_embs['valid'])], np.asarray(label['valid'])],\n",
    "            callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f59120ab-f66e-4d18-b27a-fb98bee8e9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 9ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg     0.7206    0.7177    0.7192       248\n",
      "         Pos     0.4901    0.7071    0.5789       140\n",
      "         Neu     0.5000    0.0580    0.1039        69\n",
      "\n",
      "    accuracy                         0.6149       457\n",
      "   macro avg     0.5702    0.4943    0.4673       457\n",
      "weighted avg     0.6167    0.6149    0.5833       457\n",
      "\n",
      "[[178  67   3]\n",
      " [ 40  99   1]\n",
      " [ 29  36   4]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./res/multi_model_concate.tf/')\n",
    "pred = model.predict([np.asarray(visual_clip['test']), np.asarray(acoustic['test']), np.asarray(bert_embs['test'])])\n",
    "predicted_test_labels = pred.argmax(axis=1)\n",
    "numeric_test_labels = np.array(label['test'])\n",
    "            \n",
    "eval_res = classification_report(numeric_test_labels, predicted_test_labels, \n",
    "                                    target_names = ['Neg', 'Pos', 'Neu'], \n",
    "                                    digits=4, output_dict=False)\n",
    "\n",
    "print(eval_res)\n",
    "\n",
    "cm = confusion_matrix(y_true=numeric_test_labels.tolist(), y_pred=predicted_test_labels.tolist())\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f4f2ab-3e90-498b-8878-67471dc8dce2",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7ff6f76-55a2-4e69-bbfe-92522ad6def2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 10, 512)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 10, 64)       98368       ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 128, 512)]   0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 36, 768)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 10, 64)       4160        ['conv1d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 63, 64)       98368       ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 34, 64)       147520      ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 34, 64)       147520      ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 10, 64)       12352       ['conv1d_7[0][0]']               \n",
      "                                                                                                  \n",
      " attention__self_1 (Attention_S  (None, 63, 32)      4193        ['conv1d_9[0][0]']               \n",
      " elf)                                                                                             \n",
      "                                                                                                  \n",
      " attention_1 (Attention)        (None, 34, 64)       0           ['conv1d_10[0][0]',              \n",
      "                                                                  'conv1d_11[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 64)           33024       ['conv1d_8[0][0]']               \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 64)          16640       ['attention__self_1[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2 (Gl  (None, 64)          0           ['conv1d_10[0][0]']              \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_3 (Gl  (None, 64)          0           ['attention_1[0][0]']            \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 256)          0           ['lstm_2[0][0]',                 \n",
      "                                                                  'bidirectional_1[0][0]',        \n",
      "                                                                  'global_average_pooling1d_2[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_average_pooling1d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " attention__self_2 (Attention_S  (None, 256)         131841      ['concatenate_1[0][0]']          \n",
      " elf)                                                                                             \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 64)           16448       ['attention__self_2[0][0]']      \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 3)            195         ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 710,629\n",
      "Trainable params: 710,629\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# './res/V_model_CNNLSTM_clip.tf'\n",
    "vis_ipt = Input((10, 512))\n",
    "vis_h = Conv1D(64, 3, 1, 'same')(vis_ipt)\n",
    "vis_h = Conv1D(64, 1, 1, 'same')(vis_h)\n",
    "vis_h = Conv1D(64, 3, 1, 'same')(vis_h)\n",
    "vis_h = LSTM(64, activation='relu')(vis_h)\n",
    "\n",
    "# './res/A_model_Att-BLSTM_wav2vec_v2.tf'\n",
    "aud_ipt = Input((128,512))\n",
    "aud_h = Conv1D(64, 3, 2)(aud_ipt)\n",
    "aud_h = Attention_Self(32)(aud_h)\n",
    "aud_h = Bidirectional(LSTM(32))(aud_h)\n",
    "\n",
    "# './res/T_model_AttCNN_bert.tf'\n",
    "tex_ipt = Input((36,768))\n",
    "tex_q = Conv1D(64, 3, 1)(tex_ipt)\n",
    "tex_v = Conv1D(64, 3, 1)(tex_ipt)\n",
    "tex_qv_attention = Attention()([tex_q, tex_v])\n",
    "tex_q = GlobalAveragePooling1D()(tex_q)\n",
    "tex_qv_attention = GlobalAveragePooling1D()(tex_qv_attention)\n",
    "# h = Concatenate()([q, qv_attention])\n",
    "\n",
    "h = Concatenate()([vis_h, aud_h, tex_q, tex_qv_attention])\n",
    "h = Attention_Self(256)(h)\n",
    "h = Dense(64)(h)\n",
    "res = Dense(3, activation='softmax')(h)\n",
    "\n",
    "model = Model(inputs=[vis_ipt, aud_ipt, tex_ipt], outputs=res)\n",
    "model.compile(optimizer='Adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics='acc')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2277907c-a192-47b5-aa5a-0670d84f7b76",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "86/86 [==============================] - ETA: 0s - loss: 1.0400 - acc: 0.5044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_selfatt.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_selfatt.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 11s 107ms/step - loss: 1.0400 - acc: 0.5044 - val_loss: 1.0074 - val_acc: 0.5439\n",
      "Epoch 2/30\n",
      "86/86 [==============================] - 2s 20ms/step - loss: 0.9961 - acc: 0.5424 - val_loss: 1.0334 - val_acc: 0.5439\n",
      "Epoch 3/30\n",
      "84/86 [============================>.] - ETA: 0s - loss: 1.0039 - acc: 0.5365"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_selfatt.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_selfatt.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 8s 91ms/step - loss: 1.0053 - acc: 0.5336 - val_loss: 0.9849 - val_acc: 0.5439\n",
      "Epoch 4/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.9915 - acc: 0.5424 - val_loss: 0.9893 - val_acc: 0.5439\n",
      "Epoch 5/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.9912 - acc: 0.5424 - val_loss: 0.9921 - val_acc: 0.5439\n",
      "Epoch 6/30\n",
      "86/86 [==============================] - 2s 26ms/step - loss: 0.9907 - acc: 0.5395 - val_loss: 0.9966 - val_acc: 0.5439\n",
      "Epoch 7/30\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.9914 - acc: 0.5373"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_selfatt.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_selfatt.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 9s 100ms/step - loss: 0.9914 - acc: 0.5373 - val_loss: 0.9828 - val_acc: 0.5439\n",
      "Epoch 8/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.9879 - acc: 0.5395 - val_loss: 1.1069 - val_acc: 0.3048\n",
      "Epoch 9/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.9963 - acc: 0.5175 - val_loss: 1.0706 - val_acc: 0.4978\n",
      "Epoch 10/30\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.9819 - acc: 0.5350"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_selfatt.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_selfatt.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 8s 92ms/step - loss: 0.9825 - acc: 0.5358 - val_loss: 0.9814 - val_acc: 0.5373\n",
      "Epoch 11/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.9692 - acc: 0.5643 - val_loss: 1.0084 - val_acc: 0.5088\n",
      "Epoch 12/30\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.9076 - acc: 0.6007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_selfatt.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_selfatt.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 8s 91ms/step - loss: 0.9079 - acc: 0.6001 - val_loss: 0.9691 - val_acc: 0.5592\n",
      "Epoch 13/30\n",
      "86/86 [==============================] - 2s 19ms/step - loss: 0.8708 - acc: 0.6243 - val_loss: 0.9900 - val_acc: 0.5570\n",
      "Epoch 14/30\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.8363 - acc: 0.6462"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_selfatt.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_selfatt.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 8s 93ms/step - loss: 0.8363 - acc: 0.6462 - val_loss: 0.9364 - val_acc: 0.5768\n",
      "Epoch 15/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.8010 - acc: 0.6469 - val_loss: 1.0247 - val_acc: 0.5724\n",
      "Epoch 16/30\n",
      "86/86 [==============================] - 2s 19ms/step - loss: 0.7939 - acc: 0.6608 - val_loss: 1.1626 - val_acc: 0.4693\n",
      "Epoch 17/30\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.7333 - acc: 0.6718 - val_loss: 1.0254 - val_acc: 0.5504\n",
      "Epoch 18/30\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.7269 - acc: 0.7083 - val_loss: 1.1742 - val_acc: 0.5570\n",
      "Epoch 19/30\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.7239 - acc: 0.7039 - val_loss: 1.1177 - val_acc: 0.5461\n",
      "Epoch 20/30\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.6896 - acc: 0.7010 - val_loss: 1.1680 - val_acc: 0.5548\n",
      "Epoch 21/30\n",
      "86/86 [==============================] - 2s 24ms/step - loss: 0.6497 - acc: 0.7376 - val_loss: 1.1456 - val_acc: 0.5263\n",
      "Epoch 22/30\n",
      "86/86 [==============================] - 2s 18ms/step - loss: 0.6297 - acc: 0.7537 - val_loss: 1.2517 - val_acc: 0.5548\n",
      "Epoch 23/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.5844 - acc: 0.7639 - val_loss: 1.2852 - val_acc: 0.5526\n",
      "Epoch 24/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.5765 - acc: 0.7610 - val_loss: 1.4874 - val_acc: 0.5329\n",
      "Epoch 25/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.5389 - acc: 0.7800 - val_loss: 1.6238 - val_acc: 0.5548\n",
      "Epoch 26/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.5505 - acc: 0.7719 - val_loss: 1.5904 - val_acc: 0.5285\n",
      "Epoch 27/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.5455 - acc: 0.7829 - val_loss: 1.4048 - val_acc: 0.5417\n",
      "Epoch 28/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.5404 - acc: 0.7734 - val_loss: 1.4387 - val_acc: 0.5263\n",
      "Epoch 29/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.5033 - acc: 0.7895 - val_loss: 1.8155 - val_acc: 0.4956\n",
      "Epoch 30/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.4664 - acc: 0.7961 - val_loss: 1.9775 - val_acc: 0.5439\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fea742fd780>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_list = [ModelCheckpoint(filepath='./res/multi_model_selfatt.tf', monitor='val_loss', save_best_only=True, save_freq='epoch')]\n",
    "\n",
    "model.fit(x=[np.asarray(visual_clip['train']), np.asarray(acoustic['train']), np.asarray(bert_embs['train'])], y=np.asarray(label['train']), batch_size=16, epochs=30, \n",
    "            validation_data=[[np.asarray(visual_clip['valid']), np.asarray(acoustic['valid']), np.asarray(bert_embs['valid'])], np.asarray(label['valid'])],\n",
    "            callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "109ddb73-db2e-4773-840f-bff6940f3ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg     0.6158    0.8468    0.7131       248\n",
      "         Pos     0.4914    0.4071    0.4453       140\n",
      "         Neu     0.0000    0.0000    0.0000        69\n",
      "\n",
      "    accuracy                         0.5842       457\n",
      "   macro avg     0.3691    0.4180    0.3861       457\n",
      "weighted avg     0.4847    0.5842    0.5234       457\n",
      "\n",
      "[[210  38   0]\n",
      " [ 83  57   0]\n",
      " [ 48  21   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./res/multi_model_selfatt.tf/')\n",
    "pred = model.predict([np.asarray(visual_clip['test']), np.asarray(acoustic['test']), np.asarray(bert_embs['test'])])\n",
    "predicted_test_labels = pred.argmax(axis=1)\n",
    "numeric_test_labels = np.array(label['test'])\n",
    "            \n",
    "eval_res = classification_report(numeric_test_labels, predicted_test_labels, \n",
    "                                    target_names = ['Neg', 'Pos', 'Neu'], \n",
    "                                    digits=4, output_dict=False)\n",
    "\n",
    "print(eval_res)\n",
    "\n",
    "cm = confusion_matrix(y_true=numeric_test_labels.tolist(), y_pred=predicted_test_labels.tolist())\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "137981d9-6ff1-42c8-999c-875d2658362d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 10, 512)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 10, 64)       98368       ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 128, 512)]   0           []                               \n",
      "                                                                                                  \n",
      " input_9 (InputLayer)           [(None, 36, 768)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 10, 64)       4160        ['conv1d_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 63, 64)       98368       ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 34, 64)       147520      ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 34, 64)       147520      ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 10, 64)       12352       ['conv1d_13[0][0]']              \n",
      "                                                                                                  \n",
      " attention__self_3 (Attention_S  (None, 63, 32)      4193        ['conv1d_15[0][0]']              \n",
      " elf)                                                                                             \n",
      "                                                                                                  \n",
      " attention_2 (Attention)        (None, 34, 64)       0           ['conv1d_16[0][0]',              \n",
      "                                                                  'conv1d_17[0][0]']              \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)                  (None, 64)           33024       ['conv1d_14[0][0]']              \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, 64)          16640       ['attention__self_3[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_4 (Gl  (None, 64)          0           ['conv1d_16[0][0]']              \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_5 (Gl  (None, 64)          0           ['attention_2[0][0]']            \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 256)          0           ['lstm_4[0][0]',                 \n",
      "                                                                  'bidirectional_2[0][0]',        \n",
      "                                                                  'global_average_pooling1d_4[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_average_pooling1d_5[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " attention_3 (Attention)        (None, 256)          1           ['concatenate_2[0][0]',          \n",
      "                                                                  'concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 64)           16448       ['attention_3[0][0]']            \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 3)            195         ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 578,789\n",
      "Trainable params: 578,789\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# './res/V_model_CNNLSTM_clip.tf'\n",
    "vis_ipt = Input((10, 512))\n",
    "vis_h = Conv1D(64, 3, 1, 'same')(vis_ipt)\n",
    "vis_h = Conv1D(64, 1, 1, 'same')(vis_h)\n",
    "vis_h = Conv1D(64, 3, 1, 'same')(vis_h)\n",
    "vis_h = LSTM(64, activation='relu')(vis_h)\n",
    "\n",
    "# './res/A_model_Att-BLSTM_wav2vec_v2.tf'\n",
    "aud_ipt = Input((128,512))\n",
    "aud_h = Conv1D(64, 3, 2)(aud_ipt)\n",
    "aud_h = Attention_Self(32)(aud_h)\n",
    "aud_h = Bidirectional(LSTM(32))(aud_h)\n",
    "\n",
    "# './res/T_model_AttCNN_bert.tf'\n",
    "tex_ipt = Input((36,768))\n",
    "tex_q = Conv1D(64, 3, 1)(tex_ipt)\n",
    "tex_v = Conv1D(64, 3, 1)(tex_ipt)\n",
    "tex_qv_attention = Attention()([tex_q, tex_v])\n",
    "tex_q = GlobalAveragePooling1D()(tex_q)\n",
    "tex_qv_attention = GlobalAveragePooling1D()(tex_qv_attention)\n",
    "# h = Concatenate()([q, qv_attention])\n",
    "\n",
    "h = Concatenate()([vis_h, aud_h, tex_q, tex_qv_attention])\n",
    "h = Attention(256)([h,h])\n",
    "h = Dense(64)(h)\n",
    "res = Dense(3, activation='softmax')(h)\n",
    "\n",
    "model = Model(inputs=[vis_ipt, aud_ipt, tex_ipt], outputs=res)\n",
    "model.compile(optimizer='Adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics='acc')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b147b8c-8164-4e07-8945-7ea853698743",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "86/86 [==============================] - ETA: 0s - loss: 1.0464 - acc: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_selfattv2.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_selfattv2.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 10s 98ms/step - loss: 1.0464 - acc: 0.5000 - val_loss: 0.9966 - val_acc: 0.5044\n",
      "Epoch 2/30\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.9031 - acc: 0.6015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_selfattv2.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_selfattv2.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 8s 94ms/step - loss: 0.9020 - acc: 0.6038 - val_loss: 0.9256 - val_acc: 0.5789\n",
      "Epoch 3/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.7575 - acc: 0.6835 - val_loss: 1.1618 - val_acc: 0.5965\n",
      "Epoch 4/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.6917 - acc: 0.7237 - val_loss: 1.0997 - val_acc: 0.5570\n",
      "Epoch 5/30\n",
      "86/86 [==============================] - 2s 18ms/step - loss: 1.0478 - acc: 0.5811 - val_loss: 1.1225 - val_acc: 0.4912\n",
      "Epoch 6/30\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.7934 - acc: 0.6769 - val_loss: 1.1670 - val_acc: 0.5044\n",
      "Epoch 7/30\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.9022 - acc: 0.6404 - val_loss: 1.0362 - val_acc: 0.5154\n",
      "Epoch 8/30\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.8188 - acc: 0.6849 - val_loss: 1.0809 - val_acc: 0.5482\n",
      "Epoch 9/30\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.7611 - acc: 0.6864 - val_loss: 0.9948 - val_acc: 0.6118\n",
      "Epoch 10/30\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.7087 - acc: 0.7208 - val_loss: 1.1805 - val_acc: 0.5219\n",
      "Epoch 11/30\n",
      "86/86 [==============================] - 2s 18ms/step - loss: 0.6368 - acc: 0.7442 - val_loss: 1.0239 - val_acc: 0.6184\n",
      "Epoch 12/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.6193 - acc: 0.7654 - val_loss: 1.2444 - val_acc: 0.5175\n",
      "Epoch 13/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.4987 - acc: 0.8019 - val_loss: 1.1433 - val_acc: 0.5724\n",
      "Epoch 14/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.4225 - acc: 0.8480 - val_loss: 1.2161 - val_acc: 0.5614\n",
      "Epoch 15/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.5177 - acc: 0.8092 - val_loss: 1.2593 - val_acc: 0.5197\n",
      "Epoch 16/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.4812 - acc: 0.8319 - val_loss: 1.3003 - val_acc: 0.5592\n",
      "Epoch 17/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.4381 - acc: 0.8363 - val_loss: 1.3417 - val_acc: 0.5461\n",
      "Epoch 18/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.5555 - acc: 0.8501 - val_loss: 3.0100 - val_acc: 0.5022\n",
      "Epoch 19/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 2.1472 - acc: 0.5614 - val_loss: 1.3538 - val_acc: 0.5110\n",
      "Epoch 20/30\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.9584 - acc: 0.6528 - val_loss: 1.2188 - val_acc: 0.5022\n",
      "Epoch 21/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.6988 - acc: 0.7186 - val_loss: 1.2177 - val_acc: 0.4715\n",
      "Epoch 22/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.6851 - acc: 0.7317 - val_loss: 1.1333 - val_acc: 0.5592\n",
      "Epoch 23/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.5660 - acc: 0.7939 - val_loss: 1.3363 - val_acc: 0.5154\n",
      "Epoch 24/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.5978 - acc: 0.7844 - val_loss: 1.2001 - val_acc: 0.5219\n",
      "Epoch 25/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.6438 - acc: 0.7551 - val_loss: 1.3027 - val_acc: 0.5263\n",
      "Epoch 26/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.6080 - acc: 0.7602 - val_loss: 1.3075 - val_acc: 0.5373\n",
      "Epoch 27/30\n",
      "86/86 [==============================] - 2s 22ms/step - loss: 0.5117 - acc: 0.8107 - val_loss: 1.3554 - val_acc: 0.5439\n",
      "Epoch 28/30\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.5676 - acc: 0.8041 - val_loss: 1.4407 - val_acc: 0.4934\n",
      "Epoch 29/30\n",
      "86/86 [==============================] - 2s 26ms/step - loss: 0.5714 - acc: 0.7829 - val_loss: 1.4033 - val_acc: 0.5175\n",
      "Epoch 30/30\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.5343 - acc: 0.8041 - val_loss: 1.4991 - val_acc: 0.5044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7feac4183160>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_list = [ModelCheckpoint(filepath='./res/multi_model_selfattv2.tf', monitor='val_loss', save_best_only=True, save_freq='epoch')]\n",
    "\n",
    "model.fit(x=[np.asarray(visual_clip['train']), np.asarray(acoustic['train']), np.asarray(bert_embs['train'])], y=np.asarray(label['train']), batch_size=16, epochs=30, \n",
    "            validation_data=[[np.asarray(visual_clip['valid']), np.asarray(acoustic['valid']), np.asarray(bert_embs['valid'])], np.asarray(label['valid'])],\n",
    "            callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b75cff87-6b18-47ab-845e-959b058649d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg     0.6700    0.8024    0.7303       248\n",
      "         Pos     0.5380    0.6071    0.5705       140\n",
      "         Neu     0.0000    0.0000    0.0000        69\n",
      "\n",
      "    accuracy                         0.6214       457\n",
      "   macro avg     0.4027    0.4699    0.4336       457\n",
      "weighted avg     0.5284    0.6214    0.5711       457\n",
      "\n",
      "[[199  48   1]\n",
      " [ 54  85   1]\n",
      " [ 44  25   0]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./res/multi_model_selfattv2.tf/')\n",
    "pred = model.predict([np.asarray(visual_clip['test']), np.asarray(acoustic['test']), np.asarray(bert_embs['test'])])\n",
    "predicted_test_labels = pred.argmax(axis=1)\n",
    "numeric_test_labels = np.array(label['test'])\n",
    "            \n",
    "eval_res = classification_report(numeric_test_labels, predicted_test_labels, \n",
    "                                    target_names = ['Neg', 'Pos', 'Neu'], \n",
    "                                    digits=4, output_dict=False)\n",
    "\n",
    "print(eval_res)\n",
    "\n",
    "cm = confusion_matrix(y_true=numeric_test_labels.tolist(), y_pred=predicted_test_labels.tolist())\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c3e9a1-fec8-4dfd-a389-8a8b0993ef6c",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "330bf42e-fa89-436f-8525-a448f5551012",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_Cross(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(Attention_Cross, self).__init__(**kwargs)\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.S = tf.keras.layers.Dense(1)\n",
    "        self.units = units\n",
    "\n",
    "    def call(self, features1, features2):\n",
    "        features2_ = tf.expand_dims(features2, 1)\n",
    "        v = self.W1(features1)\n",
    "        # v_ = self.W1(features2)\n",
    "        q =  self.W2(features2_)\n",
    "        score = tf.nn.tanh(q + v)\n",
    "        attention_weights = tf.nn.softmax(self.S(score), axis=1)\n",
    "        # ATTN = attention_weights * (v+v_)\n",
    "        ATTN = attention_weights * v\n",
    "        ATTN = tf.reduce_sum(ATTN, axis=1)\n",
    "        \n",
    "#         features2_ = tf.expand_dims(features2, 1)\n",
    "#         score = tf.nn.tanh(self.W1(features1) + self.W2(features2_))\n",
    "#         attention_weights = tf.nn.softmax(self.S(score), axis=1)\n",
    "#         ATTN = attention_weights * (features1 + features2)\n",
    "#         ATTN = tf.reduce_sum(ATTN, axis=1)\n",
    "        \n",
    "        return ATTN\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(Attention_Cross, self).get_config()\n",
    "        config.update({\"units\": self.units})\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0e5a047-2e7c-4200-978c-b3144c3a9cd9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 10, 512)]    0           []                               \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 36, 768)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 10, 64)       98368       ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)          [(None, 128, 512)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 34, 64)       147520      ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 34, 64)       147520      ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 10, 64)       4160        ['conv1d_18[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 63, 64)       98368       ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " attention_4 (Attention)        (None, 34, 64)       0           ['conv1d_22[0][0]',              \n",
      "                                                                  'conv1d_23[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 10, 64)       12352       ['conv1d_19[0][0]']              \n",
      "                                                                                                  \n",
      " attention__self_4 (Attention_S  (None, 63, 32)      4193        ['conv1d_21[0][0]']              \n",
      " elf)                                                                                             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_6 (Gl  (None, 64)          0           ['conv1d_22[0][0]']              \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_7 (Gl  (None, 64)          0           ['attention_4[0][0]']            \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)                  (None, 64)           33024       ['conv1d_20[0][0]']              \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirectional  (None, 64)          16640       ['attention__self_4[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 128)          0           ['global_average_pooling1d_6[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_average_pooling1d_7[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 128)          0           ['lstm_6[0][0]',                 \n",
      "                                                                  'bidirectional_3[0][0]']        \n",
      "                                                                                                  \n",
      " attention__cross (Attention_Cr  (None, 128)         33153       ['concatenate_3[0][0]',          \n",
      " oss)                                                             'concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 3)            387         ['attention__cross[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 595,685\n",
      "Trainable params: 595,685\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# './res/V_model_CNNLSTM_clip.tf'\n",
    "vis_ipt = Input((10, 512))\n",
    "vis_h = Conv1D(64, 3, 1, 'same')(vis_ipt)\n",
    "vis_h = Conv1D(64, 1, 1, 'same')(vis_h)\n",
    "vis_h = Conv1D(64, 3, 1, 'same')(vis_h)\n",
    "vis_h = LSTM(64, activation='relu')(vis_h)\n",
    "\n",
    "# './res/A_model_Att-BLSTM_wav2vec_v2.tf'\n",
    "aud_ipt = Input((128,512))\n",
    "aud_h = Conv1D(64, 3, 2)(aud_ipt)\n",
    "aud_h = Attention_Self(32)(aud_h)\n",
    "aud_h = Bidirectional(LSTM(32))(aud_h)\n",
    "\n",
    "# './res/T_model_AttCNN_bert.tf'\n",
    "tex_ipt = Input((36,768))\n",
    "tex_q = Conv1D(64, 3, 1)(tex_ipt)\n",
    "tex_v = Conv1D(64, 3, 1)(tex_ipt)\n",
    "tex_qv_attention = Attention()([tex_q, tex_v])\n",
    "tex_q = GlobalAveragePooling1D()(tex_q)\n",
    "tex_qv_attention = GlobalAveragePooling1D()(tex_qv_attention)\n",
    "# h = Concatenate()([q, qv_attention])\n",
    "\n",
    "v = Concatenate()([tex_q, tex_qv_attention])\n",
    "q = Concatenate()([vis_h, aud_h])\n",
    "h = Attention_Cross(128)(v, q)\n",
    "# h = Dense(64)(h)\n",
    "res = Dense(3, activation='softmax')(h)\n",
    "\n",
    "model = Model(inputs=[vis_ipt, aud_ipt, tex_ipt], outputs=res)\n",
    "model.compile(optimizer='Adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics='acc')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4d75e4d-122f-4b6d-b7e9-9ddc08eaf1f8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "84/86 [============================>.] - ETA: 0s - loss: 1.0708 - acc: 0.5238"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossatt.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossatt.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 11s 103ms/step - loss: 1.0685 - acc: 0.5256 - val_loss: 1.0383 - val_acc: 0.5439\n",
      "Epoch 2/30\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.9906 - acc: 0.5402"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossatt.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossatt.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 8s 98ms/step - loss: 0.9901 - acc: 0.5402 - val_loss: 0.9977 - val_acc: 0.5439\n",
      "Epoch 3/30\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.9776 - acc: 0.5424"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossatt.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossatt.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 8s 96ms/step - loss: 0.9776 - acc: 0.5424 - val_loss: 0.9693 - val_acc: 0.5439\n",
      "Epoch 4/30\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.9618 - acc: 0.5519"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossatt.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossatt.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 8s 90ms/step - loss: 0.9618 - acc: 0.5519 - val_loss: 0.9525 - val_acc: 0.5373\n",
      "Epoch 5/30\n",
      "86/86 [==============================] - 2s 24ms/step - loss: 0.9250 - acc: 0.5899 - val_loss: 1.0056 - val_acc: 0.4978\n",
      "Epoch 6/30\n",
      "86/86 [==============================] - 2s 24ms/step - loss: 0.9812 - acc: 0.5446 - val_loss: 0.9649 - val_acc: 0.5439\n",
      "Epoch 7/30\n",
      "86/86 [==============================] - 2s 24ms/step - loss: 0.9677 - acc: 0.5468 - val_loss: 1.0056 - val_acc: 0.5439\n",
      "Epoch 8/30\n",
      "86/86 [==============================] - 2s 21ms/step - loss: 1.0078 - acc: 0.5329 - val_loss: 1.0370 - val_acc: 0.3465\n",
      "Epoch 9/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 1.0127 - acc: 0.5058 - val_loss: 1.0350 - val_acc: 0.5088\n",
      "Epoch 10/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 1.0130 - acc: 0.5278 - val_loss: 0.9921 - val_acc: 0.5439\n",
      "Epoch 11/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 1.0412 - acc: 0.5095 - val_loss: 1.0624 - val_acc: 0.3333\n",
      "Epoch 12/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 1.0042 - acc: 0.5066 - val_loss: 1.0023 - val_acc: 0.5439\n",
      "Epoch 13/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 1.0035 - acc: 0.5285 - val_loss: 1.0001 - val_acc: 0.5439\n",
      "Epoch 14/30\n",
      "86/86 [==============================] - 2s 18ms/step - loss: 1.0011 - acc: 0.5424 - val_loss: 0.9995 - val_acc: 0.5439\n",
      "Epoch 15/30\n",
      "86/86 [==============================] - 2s 18ms/step - loss: 1.0005 - acc: 0.5402 - val_loss: 0.9884 - val_acc: 0.5439\n",
      "Epoch 16/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.9910 - acc: 0.5424 - val_loss: 1.0070 - val_acc: 0.5263\n",
      "Epoch 17/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 1.0157 - acc: 0.5292 - val_loss: 1.3049 - val_acc: 0.3004\n",
      "Epoch 18/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 1.0138 - acc: 0.5146 - val_loss: 0.9941 - val_acc: 0.5439\n",
      "Epoch 19/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 1.0001 - acc: 0.5175 - val_loss: 1.0062 - val_acc: 0.5439\n",
      "Epoch 20/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.9979 - acc: 0.5424 - val_loss: 0.9892 - val_acc: 0.5439\n",
      "Epoch 21/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.9941 - acc: 0.5424 - val_loss: 0.9884 - val_acc: 0.5439\n",
      "Epoch 22/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.9846 - acc: 0.5417 - val_loss: 0.9932 - val_acc: 0.5439\n",
      "Epoch 23/30\n",
      "86/86 [==============================] - 2s 20ms/step - loss: 0.9781 - acc: 0.5395 - val_loss: 0.9900 - val_acc: 0.5439\n",
      "Epoch 24/30\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.9773 - acc: 0.5424 - val_loss: 0.9601 - val_acc: 0.5395\n",
      "Epoch 25/30\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.9588 - acc: 0.5409 - val_loss: 0.9709 - val_acc: 0.5439\n",
      "Epoch 26/30\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.9344 - acc: 0.5563"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossatt.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossatt.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 9s 101ms/step - loss: 0.9344 - acc: 0.5563 - val_loss: 0.9461 - val_acc: 0.5548\n",
      "Epoch 27/30\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.9210 - acc: 0.5841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossatt.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossatt.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 8s 96ms/step - loss: 0.9210 - acc: 0.5841 - val_loss: 0.9453 - val_acc: 0.5526\n",
      "Epoch 28/30\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.8885 - acc: 0.6001"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 22). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossatt.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossatt.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 8s 93ms/step - loss: 0.8885 - acc: 0.6001 - val_loss: 0.9297 - val_acc: 0.5789\n",
      "Epoch 29/30\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.8937 - acc: 0.6177 - val_loss: 0.9511 - val_acc: 0.5746\n",
      "Epoch 30/30\n",
      "86/86 [==============================] - 2s 24ms/step - loss: 0.8860 - acc: 0.6206 - val_loss: 1.0010 - val_acc: 0.4890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fea203bd2d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_list = [ModelCheckpoint(filepath='./res/multi_model_crossatt.tf', monitor='val_loss', save_best_only=True, save_freq='epoch')]\n",
    "\n",
    "model.fit(x=[np.asarray(visual_clip['train']), np.asarray(acoustic['train']), np.asarray(bert_embs['train'])], y=np.asarray(label['train']), batch_size=16, epochs=30, \n",
    "            validation_data=[[np.asarray(visual_clip['valid']), np.asarray(acoustic['valid']), np.asarray(bert_embs['valid'])], np.asarray(label['valid'])],\n",
    "            callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26f92f1a-ba96-4d45-94e4-2b6505e5a83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg     0.6961    0.7944    0.7420       248\n",
      "         Pos     0.5115    0.6357    0.5669       140\n",
      "         Neu     0.0000    0.0000    0.0000        69\n",
      "\n",
      "    accuracy                         0.6258       457\n",
      "   macro avg     0.4025    0.4767    0.4363       457\n",
      "weighted avg     0.5345    0.6258    0.5763       457\n",
      "\n",
      "[[197  51   0]\n",
      " [ 51  89   0]\n",
      " [ 35  34   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./res/multi_model_crossatt.tf/')\n",
    "pred = model.predict([np.asarray(visual_clip['test']), np.asarray(acoustic['test']), np.asarray(bert_embs['test'])])\n",
    "predicted_test_labels = pred.argmax(axis=1)\n",
    "numeric_test_labels = np.array(label['test'])\n",
    "            \n",
    "eval_res = classification_report(numeric_test_labels, predicted_test_labels, \n",
    "                                    target_names = ['Neg', 'Pos', 'Neu'], \n",
    "                                    digits=4, output_dict=False)\n",
    "\n",
    "print(eval_res)\n",
    "\n",
    "cm = confusion_matrix(y_true=numeric_test_labels.tolist(), y_pred=predicted_test_labels.tolist())\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "583b12be-0776-45bd-b3dd-2a0c402c7ebb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 10, 512)]    0           []                               \n",
      "                                                                                                  \n",
      " input_15 (InputLayer)          [(None, 36, 768)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)             (None, 10, 64)       98368       ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)          [(None, 128, 512)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d_28 (Conv1D)             (None, 34, 64)       147520      ['input_15[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_29 (Conv1D)             (None, 34, 64)       147520      ['input_15[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_25 (Conv1D)             (None, 10, 64)       4160        ['conv1d_24[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_27 (Conv1D)             (None, 63, 64)       98368       ['input_14[0][0]']               \n",
      "                                                                                                  \n",
      " attention_5 (Attention)        (None, 34, 64)       0           ['conv1d_28[0][0]',              \n",
      "                                                                  'conv1d_29[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)             (None, 10, 64)       12352       ['conv1d_25[0][0]']              \n",
      "                                                                                                  \n",
      " attention__self_5 (Attention_S  (None, 63, 32)      4193        ['conv1d_27[0][0]']              \n",
      " elf)                                                                                             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_8 (Gl  (None, 64)          0           ['conv1d_28[0][0]']              \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_9 (Gl  (None, 64)          0           ['attention_5[0][0]']            \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " lstm_8 (LSTM)                  (None, 64)           33024       ['conv1d_26[0][0]']              \n",
      "                                                                                                  \n",
      " bidirectional_4 (Bidirectional  (None, 64)          16640       ['attention__self_5[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 128)          0           ['global_average_pooling1d_8[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_average_pooling1d_9[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 128)          0           ['lstm_8[0][0]',                 \n",
      "                                                                  'bidirectional_4[0][0]']        \n",
      "                                                                                                  \n",
      " attention_6 (Attention)        (None, 128)          1           ['concatenate_5[0][0]',          \n",
      "                                                                  'concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 3)            387         ['attention_6[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 562,533\n",
      "Trainable params: 562,533\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# './res/V_model_CNNLSTM_clip.tf'\n",
    "vis_ipt = Input((10, 512))\n",
    "vis_h = Conv1D(64, 3, 1, 'same')(vis_ipt)\n",
    "vis_h = Conv1D(64, 1, 1, 'same')(vis_h)\n",
    "vis_h = Conv1D(64, 3, 1, 'same')(vis_h)\n",
    "vis_h = LSTM(64, activation='relu')(vis_h)\n",
    "\n",
    "# './res/A_model_Att-BLSTM_wav2vec_v2.tf'\n",
    "aud_ipt = Input((128,512))\n",
    "aud_h = Conv1D(64, 3, 2)(aud_ipt)\n",
    "aud_h = Attention_Self(32)(aud_h)\n",
    "aud_h = Bidirectional(LSTM(32))(aud_h)\n",
    "\n",
    "# './res/T_model_AttCNN_bert.tf'\n",
    "tex_ipt = Input((36,768))\n",
    "tex_q = Conv1D(64, 3, 1)(tex_ipt)\n",
    "tex_v = Conv1D(64, 3, 1)(tex_ipt)\n",
    "tex_qv_attention = Attention()([tex_q, tex_v])\n",
    "tex_q = GlobalAveragePooling1D()(tex_q)\n",
    "tex_qv_attention = GlobalAveragePooling1D()(tex_qv_attention)\n",
    "# h = Concatenate()([q, qv_attention])\n",
    "\n",
    "v = Concatenate()([tex_q, tex_qv_attention])\n",
    "q = Concatenate()([vis_h, aud_h])\n",
    "h = Attention(128)([v, q])\n",
    "# h = Dense(64)(h)\n",
    "res = Dense(3, activation='softmax')(h)\n",
    "\n",
    "model = Model(inputs=[vis_ipt, aud_ipt, tex_ipt], outputs=res)\n",
    "model.compile(optimizer='Adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics='acc')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7610657b-a43a-443a-8f3c-7da6e4451b84",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "86/86 [==============================] - ETA: 0s - loss: 1.0128 - acc: 0.5322"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossattv2.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossattv2.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 10s 96ms/step - loss: 1.0128 - acc: 0.5322 - val_loss: 1.0246 - val_acc: 0.5439\n",
      "Epoch 2/30\n",
      "83/86 [===========================>..] - ETA: 0s - loss: 1.0023 - acc: 0.5309"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossattv2.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossattv2.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 8s 90ms/step - loss: 1.0007 - acc: 0.5329 - val_loss: 1.0102 - val_acc: 0.5439\n",
      "Epoch 3/30\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.9787 - acc: 0.5424"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossattv2.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossattv2.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 8s 93ms/step - loss: 0.9781 - acc: 0.5417 - val_loss: 0.9772 - val_acc: 0.5439\n",
      "Epoch 4/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.9613 - acc: 0.5365 - val_loss: 0.9972 - val_acc: 0.5439\n",
      "Epoch 5/30\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.9359 - acc: 0.5482"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossattv2.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossattv2.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 7s 88ms/step - loss: 0.9359 - acc: 0.5482 - val_loss: 0.9695 - val_acc: 0.5482\n",
      "Epoch 6/30\n",
      "86/86 [==============================] - 2s 26ms/step - loss: 0.9204 - acc: 0.5848 - val_loss: 0.9700 - val_acc: 0.5263\n",
      "Epoch 7/30\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.8960 - acc: 0.5994"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossattv2.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossattv2.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 8s 98ms/step - loss: 0.8960 - acc: 0.5994 - val_loss: 0.9570 - val_acc: 0.5263\n",
      "Epoch 8/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.9060 - acc: 0.5958 - val_loss: 0.9581 - val_acc: 0.5439\n",
      "Epoch 9/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.8980 - acc: 0.6184 - val_loss: 0.9660 - val_acc: 0.5504\n",
      "Epoch 10/30\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.8655 - acc: 0.6481"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 16). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossattv2.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_crossattv2.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 8s 89ms/step - loss: 0.8668 - acc: 0.6477 - val_loss: 0.9552 - val_acc: 0.5592\n",
      "Epoch 11/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.8612 - acc: 0.6345 - val_loss: 0.9914 - val_acc: 0.5241\n",
      "Epoch 12/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.8360 - acc: 0.6447 - val_loss: 0.9761 - val_acc: 0.5110\n",
      "Epoch 13/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.8423 - acc: 0.6440 - val_loss: 1.0345 - val_acc: 0.5417\n",
      "Epoch 14/30\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.8483 - acc: 0.6345 - val_loss: 0.9741 - val_acc: 0.5175\n",
      "Epoch 15/30\n",
      "86/86 [==============================] - 2s 24ms/step - loss: 0.8132 - acc: 0.6784 - val_loss: 1.0308 - val_acc: 0.5197\n",
      "Epoch 16/30\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.7849 - acc: 0.6835 - val_loss: 0.9787 - val_acc: 0.5439\n",
      "Epoch 17/30\n",
      "86/86 [==============================] - 2s 27ms/step - loss: 0.7557 - acc: 0.6966 - val_loss: 1.0027 - val_acc: 0.5482\n",
      "Epoch 18/30\n",
      "86/86 [==============================] - 2s 26ms/step - loss: 0.7657 - acc: 0.7025 - val_loss: 1.0244 - val_acc: 0.5241\n",
      "Epoch 19/30\n",
      "86/86 [==============================] - 2s 26ms/step - loss: 0.7616 - acc: 0.6901 - val_loss: 1.0209 - val_acc: 0.5197\n",
      "Epoch 20/30\n",
      "86/86 [==============================] - 2s 24ms/step - loss: 0.7245 - acc: 0.7178 - val_loss: 1.0300 - val_acc: 0.5285\n",
      "Epoch 21/30\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.7388 - acc: 0.7142 - val_loss: 1.0871 - val_acc: 0.5110\n",
      "Epoch 22/30\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.7144 - acc: 0.7186 - val_loss: 1.1257 - val_acc: 0.5000\n",
      "Epoch 23/30\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.6880 - acc: 0.7332 - val_loss: 1.1058 - val_acc: 0.5110\n",
      "Epoch 24/30\n",
      "86/86 [==============================] - 2s 26ms/step - loss: 0.6869 - acc: 0.7266 - val_loss: 1.0977 - val_acc: 0.5000\n",
      "Epoch 25/30\n",
      "86/86 [==============================] - 2s 28ms/step - loss: 0.6884 - acc: 0.7325 - val_loss: 1.1423 - val_acc: 0.5044\n",
      "Epoch 26/30\n",
      "86/86 [==============================] - 2s 27ms/step - loss: 0.6577 - acc: 0.7478 - val_loss: 1.1280 - val_acc: 0.5351\n",
      "Epoch 27/30\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.6804 - acc: 0.7339 - val_loss: 1.1047 - val_acc: 0.4934\n",
      "Epoch 28/30\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.6826 - acc: 0.7310 - val_loss: 1.1023 - val_acc: 0.5285\n",
      "Epoch 29/30\n",
      "86/86 [==============================] - 2s 26ms/step - loss: 0.6435 - acc: 0.7485 - val_loss: 1.1672 - val_acc: 0.5307\n",
      "Epoch 30/30\n",
      "86/86 [==============================] - 2s 27ms/step - loss: 0.6370 - acc: 0.7515 - val_loss: 1.1689 - val_acc: 0.4956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fea743aecb0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_list = [ModelCheckpoint(filepath='./res/multi_model_crossattv2.tf', monitor='val_loss', save_best_only=True, save_freq='epoch')]\n",
    "\n",
    "model.fit(x=[np.asarray(visual_clip['train']), np.asarray(acoustic['train']), np.asarray(bert_embs['train'])], y=np.asarray(label['train']), batch_size=16, epochs=30, \n",
    "            validation_data=[[np.asarray(visual_clip['valid']), np.asarray(acoustic['valid']), np.asarray(bert_embs['valid'])], np.asarray(label['valid'])],\n",
    "            callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73326b0d-0498-4cd6-83a0-0bcb41fd1f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg     0.6107    0.7339    0.6667       248\n",
      "         Pos     0.4277    0.4857    0.4548       140\n",
      "         Neu     0.0000    0.0000    0.0000        69\n",
      "\n",
      "    accuracy                         0.5470       457\n",
      "   macro avg     0.3461    0.4065    0.3738       457\n",
      "weighted avg     0.4624    0.5470    0.5011       457\n",
      "\n",
      "[[182  66   0]\n",
      " [ 72  68   0]\n",
      " [ 44  25   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./res/multi_model_crossattv2.tf/')\n",
    "pred = model.predict([np.asarray(visual_clip['test']), np.asarray(acoustic['test']), np.asarray(bert_embs['test'])])\n",
    "predicted_test_labels = pred.argmax(axis=1)\n",
    "numeric_test_labels = np.array(label['test'])\n",
    "            \n",
    "eval_res = classification_report(numeric_test_labels, predicted_test_labels, \n",
    "                                    target_names = ['Neg', 'Pos', 'Neu'], \n",
    "                                    digits=4, output_dict=False)\n",
    "\n",
    "print(eval_res)\n",
    "\n",
    "cm = confusion_matrix(y_true=numeric_test_labels.tolist(), y_pred=predicted_test_labels.tolist())\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b72583e-58ea-418b-970d-3480e8344bc6",
   "metadata": {},
   "source": [
    "# Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d612c39-59ad-4f0a-b672-d773247f2028",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "        self.add = tf.keras.layers.Add()\n",
    "        \n",
    "        \n",
    "class CrossAttention(BaseAttention):\n",
    "    def call(self, x, context):\n",
    "        attn_output, attn_scores = self.mha(\n",
    "            query=x,\n",
    "            key=context,\n",
    "            value=context,\n",
    "            return_attention_scores=True)\n",
    "\n",
    "        # Cache the attention scores for plotting later.\n",
    "        self.last_attn_scores = attn_scores\n",
    "\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "class GlobalSelfAttention(BaseAttention):\n",
    "    def call(self, x):\n",
    "        attn_output = self.mha(\n",
    "            query=x,\n",
    "            value=x,\n",
    "            key=x)\n",
    "        x = self.add([x, attn_output])\n",
    "        x = self.layernorm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "957351a4-6023-4702-bca7-9cb991c47632",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 10, 512)]    0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 36, 768)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 10, 64)       98368       ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 128, 512)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 34, 64)       147520      ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 34, 64)       147520      ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 10, 64)       4160        ['conv1d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 63, 64)       98368       ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " attention_1 (Attention)        (None, 34, 64)       0           ['conv1d_10[0][0]',              \n",
      "                                                                  'conv1d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 10, 64)       12352       ['conv1d_7[0][0]']               \n",
      "                                                                                                  \n",
      " attention__self_1 (Attention_S  (None, 63, 32)      4193        ['conv1d_9[0][0]']               \n",
      " elf)                                                                                             \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2 (Gl  (None, 64)          0           ['conv1d_10[0][0]']              \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_3 (Gl  (None, 64)          0           ['attention_1[0][0]']            \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 64)           33024       ['conv1d_8[0][0]']               \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 64)          16640       ['attention__self_1[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_4 (TFOpLambda)  (None, 1, 64)        0           ['global_average_pooling1d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_5 (TFOpLambda)  (None, 1, 64)        0           ['global_average_pooling1d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_6 (TFOpLambda)  (None, 1, 64)        0           ['lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.expand_dims_7 (TFOpLambda)  (None, 1, 64)        0           ['bidirectional_1[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 2, 64)        0           ['tf.expand_dims_4[0][0]',       \n",
      "                                                                  'tf.expand_dims_5[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 2, 64)        0           ['tf.expand_dims_6[0][0]',       \n",
      "                                                                  'tf.expand_dims_7[0][0]']       \n",
      "                                                                                                  \n",
      " cross_attention_1 (CrossAttent  (None, 2, 64)       33344       ['concatenate_2[0][0]',          \n",
      " ion)                                                             'concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_1 (TFOpLam  (None, 64)          0           ['cross_attention_1[0][0]']      \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 3)            195         ['tf.math.reduce_mean_1[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 595,684\n",
      "Trainable params: 595,684\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# './res/V_model_CNNLSTM_clip.tf'\n",
    "vis_ipt = Input((10, 512))\n",
    "vis_h = Conv1D(64, 3, 1, 'same')(vis_ipt)\n",
    "vis_h = Conv1D(64, 1, 1, 'same')(vis_h)\n",
    "vis_h = Conv1D(64, 3, 1, 'same')(vis_h)\n",
    "vis_h = LSTM(64, activation='relu')(vis_h)\n",
    "\n",
    "# './res/A_model_Att-BLSTM_wav2vec_v2.tf'\n",
    "aud_ipt = Input((128,512))\n",
    "aud_h = Conv1D(64, 3, 2)(aud_ipt)\n",
    "aud_h = Attention_Self(32)(aud_h)\n",
    "aud_h = Bidirectional(LSTM(32))(aud_h)\n",
    "\n",
    "# './res/T_model_AttCNN_bert.tf'\n",
    "tex_ipt = Input((36,768))\n",
    "tex_q = Conv1D(64, 3, 1)(tex_ipt)\n",
    "tex_v = Conv1D(64, 3, 1)(tex_ipt)\n",
    "tex_qv_attention = Attention()([tex_q, tex_v])\n",
    "tex_q = GlobalAveragePooling1D()(tex_q)\n",
    "tex_qv_attention = GlobalAveragePooling1D()(tex_qv_attention)\n",
    "# h = Concatenate()([q, qv_attention])\n",
    "\n",
    "v = Concatenate(axis=1)([tf.expand_dims(tex_q,1), tf.expand_dims(tex_qv_attention,1)])\n",
    "q = Concatenate(axis=1)([tf.expand_dims(vis_h,1), tf.expand_dims(aud_h,1)])\n",
    "\n",
    "# h = MultiHeadAttention(num_heads=4, key_dim=32, dropout=0.2)(v, q)\n",
    "h = CrossAttention(num_heads=4, key_dim=32, dropout=0.2)(v, q)\n",
    "\n",
    "# h = Dense(64)(h)\n",
    "# res = Dense(3, activation='softmax')(h)\n",
    "res = Dense(3, activation='softmax')(tf.reduce_mean(h, 1))\n",
    "\n",
    "model = Model(inputs=[vis_ipt, aud_ipt, tex_ipt], outputs=res)\n",
    "model.compile(optimizer='Adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics='acc')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e001b45-d5a6-4e84-9342-5235d8da8c10",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "85/86 [============================>.] - ETA: 0s - loss: 1.0637 - acc: 0.5610"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 34). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_multiheadatt_cross.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_multiheadatt_cross.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 12s 113ms/step - loss: 1.0632 - acc: 0.5607 - val_loss: 0.9216 - val_acc: 0.5833\n",
      "Epoch 2/30\n",
      "86/86 [==============================] - 2s 21ms/step - loss: 0.7868 - acc: 0.6659 - val_loss: 0.9462 - val_acc: 0.5702\n",
      "Epoch 3/30\n",
      "84/86 [============================>.] - ETA: 0s - loss: 0.6799 - acc: 0.7269"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 34). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_multiheadatt_cross.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_multiheadatt_cross.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 8s 96ms/step - loss: 0.6789 - acc: 0.7266 - val_loss: 0.9148 - val_acc: 0.6513\n",
      "Epoch 4/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.5850 - acc: 0.7727 - val_loss: 0.9561 - val_acc: 0.6206\n",
      "Epoch 5/30\n",
      "86/86 [==============================] - 2s 20ms/step - loss: 0.4793 - acc: 0.8209 - val_loss: 1.1447 - val_acc: 0.6075\n",
      "Epoch 6/30\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.4230 - acc: 0.8370 - val_loss: 1.1698 - val_acc: 0.6031\n",
      "Epoch 7/30\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.4025 - acc: 0.8465 - val_loss: 1.1684 - val_acc: 0.5855\n",
      "Epoch 8/30\n",
      "86/86 [==============================] - 2s 27ms/step - loss: 0.3240 - acc: 0.8925 - val_loss: 1.2746 - val_acc: 0.5921\n",
      "Epoch 9/30\n",
      "86/86 [==============================] - 2s 27ms/step - loss: 0.2627 - acc: 0.9086 - val_loss: 1.4715 - val_acc: 0.5877\n",
      "Epoch 10/30\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.2441 - acc: 0.9130 - val_loss: 1.4080 - val_acc: 0.6009\n",
      "Epoch 11/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.2593 - acc: 0.9079 - val_loss: 1.4149 - val_acc: 0.5943\n",
      "Epoch 12/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.2187 - acc: 0.9298 - val_loss: 1.5443 - val_acc: 0.5746\n",
      "Epoch 13/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.1992 - acc: 0.9276 - val_loss: 1.5693 - val_acc: 0.5702\n",
      "Epoch 14/30\n",
      "86/86 [==============================] - 2s 19ms/step - loss: 0.1364 - acc: 0.9569 - val_loss: 1.6245 - val_acc: 0.6118\n",
      "Epoch 15/30\n",
      "86/86 [==============================] - 2s 19ms/step - loss: 0.1227 - acc: 0.9547 - val_loss: 1.7949 - val_acc: 0.6053\n",
      "Epoch 16/30\n",
      "86/86 [==============================] - 2s 22ms/step - loss: 0.1171 - acc: 0.9649 - val_loss: 1.7804 - val_acc: 0.5965\n",
      "Epoch 17/30\n",
      "86/86 [==============================] - 2s 20ms/step - loss: 0.0772 - acc: 0.9751 - val_loss: 2.0944 - val_acc: 0.5724\n",
      "Epoch 18/30\n",
      "86/86 [==============================] - 2s 19ms/step - loss: 0.0539 - acc: 0.9854 - val_loss: 1.9799 - val_acc: 0.5482\n",
      "Epoch 19/30\n",
      "86/86 [==============================] - 2s 20ms/step - loss: 0.0608 - acc: 0.9825 - val_loss: 2.1378 - val_acc: 0.6162\n",
      "Epoch 20/30\n",
      "86/86 [==============================] - 2s 20ms/step - loss: 0.1080 - acc: 0.9620 - val_loss: 1.9739 - val_acc: 0.5855\n",
      "Epoch 21/30\n",
      "86/86 [==============================] - 2s 20ms/step - loss: 0.0501 - acc: 0.9890 - val_loss: 2.0739 - val_acc: 0.6096\n",
      "Epoch 22/30\n",
      "86/86 [==============================] - 2s 21ms/step - loss: 0.0254 - acc: 0.9956 - val_loss: 2.2824 - val_acc: 0.6053\n",
      "Epoch 23/30\n",
      "86/86 [==============================] - 2s 20ms/step - loss: 0.1255 - acc: 0.9605 - val_loss: 2.0809 - val_acc: 0.5680\n",
      "Epoch 24/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.1706 - acc: 0.9342 - val_loss: 1.8927 - val_acc: 0.5789\n",
      "Epoch 25/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.1148 - acc: 0.9576 - val_loss: 2.0815 - val_acc: 0.5746\n",
      "Epoch 26/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.0884 - acc: 0.9737 - val_loss: 2.1473 - val_acc: 0.5746\n",
      "Epoch 27/30\n",
      "86/86 [==============================] - 2s 19ms/step - loss: 0.0755 - acc: 0.9773 - val_loss: 2.2024 - val_acc: 0.5461\n",
      "Epoch 28/30\n",
      "86/86 [==============================] - 2s 27ms/step - loss: 0.0829 - acc: 0.9737 - val_loss: 1.9632 - val_acc: 0.5526\n",
      "Epoch 29/30\n",
      "86/86 [==============================] - 2s 26ms/step - loss: 0.0324 - acc: 0.9942 - val_loss: 2.2537 - val_acc: 0.5811\n",
      "Epoch 30/30\n",
      "86/86 [==============================] - 2s 26ms/step - loss: 0.0212 - acc: 0.9949 - val_loss: 2.4202 - val_acc: 0.5987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1eeec5d540>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_list = [ModelCheckpoint(filepath='./res/multi_model_multiheadatt_cross.tf', monitor='val_loss', save_best_only=True, save_freq='epoch')]\n",
    "\n",
    "model.fit(x=[np.asarray(visual_clip['train']), np.asarray(acoustic['train']), np.asarray(bert_embs['train'])], \n",
    "          y=np.asarray(label['train']), batch_size=16, epochs=30,\n",
    "          validation_data=[[np.asarray(visual_clip['valid']), np.asarray(acoustic['valid']), np.asarray(bert_embs['valid'])],np.asarray(label['valid'])],\n",
    "          callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1e7ec3c-f6f8-460c-8f40-ea1a00af2d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 9ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg     0.7041    0.7581    0.7301       248\n",
      "         Pos     0.5833    0.6500    0.6149       140\n",
      "         Neu     0.2941    0.1449    0.1942        69\n",
      "\n",
      "    accuracy                         0.6324       457\n",
      "   macro avg     0.5272    0.5177    0.5130       457\n",
      "weighted avg     0.6052    0.6324    0.6139       457\n",
      "\n",
      "[[188  43  17]\n",
      " [ 42  91   7]\n",
      " [ 37  22  10]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./res/multi_model_multiheadatt_cross.tf/')\n",
    "pred = model.predict([np.asarray(visual_clip['test']), np.asarray(acoustic['test']), np.asarray(bert_embs['test'])])\n",
    "predicted_test_labels = pred.argmax(axis=1)\n",
    "numeric_test_labels = np.array(label['test'])\n",
    "            \n",
    "eval_res = classification_report(numeric_test_labels, predicted_test_labels, \n",
    "                                    target_names = ['Neg', 'Pos', 'Neu'], \n",
    "                                    digits=4, output_dict=False)\n",
    "\n",
    "print(eval_res)\n",
    "\n",
    "cm = confusion_matrix(y_true=numeric_test_labels.tolist(), y_pred=predicted_test_labels.tolist())\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a8debd1-e8b5-465c-b914-60dce5c53719",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-18 12:30:25.491768: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-18 12:30:25.492593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 12:30:25.492737: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 12:30:25.492804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 12:30:25.833245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 12:30:25.833388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 12:30:25.833467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-18 12:30:25.833539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14217 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 10, 512)]    0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 36, 768)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 10, 64)       98368       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 128, 512)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 34, 64)       147520      ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 34, 64)       147520      ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 10, 64)       4160        ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 63, 64)       98368       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " attention (Attention)          (None, 34, 64)       0           ['conv1d_4[0][0]',               \n",
      "                                                                  'conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 10, 64)       12352       ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " attention__self (Attention_Sel  (None, 63, 32)      4193        ['conv1d_3[0][0]']               \n",
      " f)                                                                                               \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 64)          0           ['conv1d_4[0][0]']               \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 64)          0           ['attention[0][0]']              \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 64)           33024       ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 64)           16640       ['attention__self[0][0]']        \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 1, 64)        0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_1 (TFOpLambda)  (None, 1, 64)        0           ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_2 (TFOpLambda)  (None, 1, 64)        0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " tf.expand_dims_3 (TFOpLambda)  (None, 1, 64)        0           ['bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 4, 64)        0           ['tf.expand_dims[0][0]',         \n",
      "                                                                  'tf.expand_dims_1[0][0]',       \n",
      "                                                                  'tf.expand_dims_2[0][0]',       \n",
      "                                                                  'tf.expand_dims_3[0][0]']       \n",
      "                                                                                                  \n",
      " global_self_attention (GlobalS  (None, 4, 64)       33344       ['concatenate[0][0]']            \n",
      " elfAttention)                                                                                    \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  (None, 64)          0           ['global_self_attention[0][0]']  \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 3)            195         ['tf.math.reduce_mean[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 595,684\n",
      "Trainable params: 595,684\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# './res/V_model_CNNLSTM_clip.tf'\n",
    "vis_ipt = Input((10, 512))\n",
    "vis_h = Conv1D(64, 3, 1, 'same')(vis_ipt)\n",
    "vis_h = Conv1D(64, 1, 1, 'same')(vis_h)\n",
    "vis_h = Conv1D(64, 3, 1, 'same')(vis_h)\n",
    "vis_h = LSTM(64, activation='relu')(vis_h)\n",
    "\n",
    "# './res/A_model_Att-BLSTM_wav2vec_v2.tf'\n",
    "aud_ipt = Input((128,512))\n",
    "aud_h = Conv1D(64, 3, 2)(aud_ipt)\n",
    "aud_h = Attention_Self(32)(aud_h)\n",
    "aud_h = Bidirectional(LSTM(32))(aud_h)\n",
    "\n",
    "# './res/T_model_AttCNN_bert.tf'\n",
    "tex_ipt = Input((36,768))\n",
    "tex_q = Conv1D(64, 3, 1)(tex_ipt)\n",
    "tex_v = Conv1D(64, 3, 1)(tex_ipt)\n",
    "tex_qv_attention = Attention()([tex_q, tex_v])\n",
    "tex_q = GlobalAveragePooling1D()(tex_q)\n",
    "tex_qv_attention = GlobalAveragePooling1D()(tex_qv_attention)\n",
    "\n",
    "h = Concatenate(axis=1)([tf.expand_dims(tex_q,1), tf.expand_dims(tex_qv_attention,1), tf.expand_dims(vis_h,1), tf.expand_dims(aud_h,1)])\n",
    "\n",
    "h = GlobalSelfAttention(num_heads=4, key_dim=32, dropout=0.2)(h)\n",
    "\n",
    "# h = Dense(64)(h)\n",
    "# res = Dense(3, activation='softmax')(h)\n",
    "res = Dense(3, activation='softmax')(tf.reduce_mean(h, 1))\n",
    "\n",
    "model = Model(inputs=[vis_ipt, aud_ipt, tex_ipt], outputs=res)\n",
    "model.compile(optimizer='Adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics='acc')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e01fe14-a180-4a85-ab7f-085963d71586",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-18 12:30:30.087430: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8500\n",
      "2022-10-18 12:30:30.444872: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - ETA: 0s - loss: 1.0100 - acc: 0.5482"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 34). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_multiheadatt_global.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_multiheadatt_global.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 13s 110ms/step - loss: 1.0100 - acc: 0.5482 - val_loss: 0.8918 - val_acc: 0.6338\n",
      "Epoch 2/30\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.7572 - acc: 0.6835"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 34). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_multiheadatt_global.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/multi_model_multiheadatt_global.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 8s 99ms/step - loss: 0.7572 - acc: 0.6835 - val_loss: 0.8591 - val_acc: 0.6162\n",
      "Epoch 3/30\n",
      "86/86 [==============================] - 2s 23ms/step - loss: 0.6482 - acc: 0.7456 - val_loss: 0.9214 - val_acc: 0.5943\n",
      "Epoch 4/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.5434 - acc: 0.7917 - val_loss: 0.9432 - val_acc: 0.5943\n",
      "Epoch 5/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.4453 - acc: 0.8450 - val_loss: 0.9710 - val_acc: 0.6338\n",
      "Epoch 6/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.3733 - acc: 0.8545 - val_loss: 1.0133 - val_acc: 0.6096\n",
      "Epoch 7/30\n",
      "86/86 [==============================] - 2s 21ms/step - loss: 0.3253 - acc: 0.8933 - val_loss: 1.3031 - val_acc: 0.5811\n",
      "Epoch 8/30\n",
      "86/86 [==============================] - 2s 21ms/step - loss: 0.3327 - acc: 0.8713 - val_loss: 1.2189 - val_acc: 0.5943\n",
      "Epoch 9/30\n",
      "86/86 [==============================] - 2s 20ms/step - loss: 0.2360 - acc: 0.9115 - val_loss: 1.4088 - val_acc: 0.5943\n",
      "Epoch 10/30\n",
      "86/86 [==============================] - 2s 18ms/step - loss: 0.2213 - acc: 0.9240 - val_loss: 1.5571 - val_acc: 0.5702\n",
      "Epoch 11/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.2406 - acc: 0.9064 - val_loss: 1.5063 - val_acc: 0.6009\n",
      "Epoch 12/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.2030 - acc: 0.9254 - val_loss: 1.4826 - val_acc: 0.6162\n",
      "Epoch 13/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.1533 - acc: 0.9444 - val_loss: 2.0060 - val_acc: 0.5702\n",
      "Epoch 14/30\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.1997 - acc: 0.9254 - val_loss: 1.5863 - val_acc: 0.5943\n",
      "Epoch 15/30\n",
      "86/86 [==============================] - 2s 27ms/step - loss: 0.1084 - acc: 0.9635 - val_loss: 1.9347 - val_acc: 0.5855\n",
      "Epoch 16/30\n",
      "86/86 [==============================] - 2s 26ms/step - loss: 0.1618 - acc: 0.9474 - val_loss: 1.8029 - val_acc: 0.5899\n",
      "Epoch 17/30\n",
      "86/86 [==============================] - 2s 25ms/step - loss: 0.1013 - acc: 0.9620 - val_loss: 2.1476 - val_acc: 0.5768\n",
      "Epoch 18/30\n",
      "86/86 [==============================] - 2s 24ms/step - loss: 0.1657 - acc: 0.9386 - val_loss: 1.8128 - val_acc: 0.5987\n",
      "Epoch 19/30\n",
      "86/86 [==============================] - 2s 20ms/step - loss: 0.1133 - acc: 0.9635 - val_loss: 2.1327 - val_acc: 0.5702\n",
      "Epoch 20/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.0808 - acc: 0.9722 - val_loss: 2.2080 - val_acc: 0.6272\n",
      "Epoch 21/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.0556 - acc: 0.9788 - val_loss: 2.3523 - val_acc: 0.6228\n",
      "Epoch 22/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.1016 - acc: 0.9678 - val_loss: 2.1730 - val_acc: 0.5921\n",
      "Epoch 23/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.2246 - acc: 0.9254 - val_loss: 1.8599 - val_acc: 0.6118\n",
      "Epoch 24/30\n",
      "86/86 [==============================] - 2s 18ms/step - loss: 0.1941 - acc: 0.9357 - val_loss: 1.8267 - val_acc: 0.5724\n",
      "Epoch 25/30\n",
      "86/86 [==============================] - 2s 19ms/step - loss: 0.1556 - acc: 0.9408 - val_loss: 1.7775 - val_acc: 0.5746\n",
      "Epoch 26/30\n",
      "86/86 [==============================] - 2s 18ms/step - loss: 0.0790 - acc: 0.9751 - val_loss: 2.2294 - val_acc: 0.5658\n",
      "Epoch 27/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.0473 - acc: 0.9854 - val_loss: 2.8290 - val_acc: 0.5482\n",
      "Epoch 28/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.0516 - acc: 0.9810 - val_loss: 2.7021 - val_acc: 0.5899\n",
      "Epoch 29/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.0250 - acc: 0.9934 - val_loss: 2.8087 - val_acc: 0.6096\n",
      "Epoch 30/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.0184 - acc: 0.9963 - val_loss: 3.2362 - val_acc: 0.5789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0ad9474be0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_list = [ModelCheckpoint(filepath='./res/multi_model_multiheadatt_global.tf', monitor='val_loss', save_best_only=True, save_freq='epoch')]\n",
    "\n",
    "model.fit(x=[np.asarray(visual_clip['train']), np.asarray(acoustic['train']), np.asarray(bert_embs['train'])], \n",
    "          y=np.asarray(label['train']), batch_size=16, epochs=30,\n",
    "          validation_data=[[np.asarray(visual_clip['valid']), np.asarray(acoustic['valid']), np.asarray(bert_embs['valid'])],np.asarray(label['valid'])],\n",
    "          callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f37bb6e-aeef-4310-85c4-7643471056b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg     0.6803    0.8750    0.7654       248\n",
      "         Pos     0.6667    0.5286    0.5896       140\n",
      "         Neu     0.2222    0.0870    0.1250        69\n",
      "\n",
      "    accuracy                         0.6499       457\n",
      "   macro avg     0.5230    0.4968    0.4934       457\n",
      "weighted avg     0.6069    0.6499    0.6149       457\n",
      "\n",
      "[[217  25   6]\n",
      " [ 51  74  15]\n",
      " [ 51  12   6]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./res/multi_model_multiheadatt_global.tf/')\n",
    "pred = model.predict([np.asarray(visual_clip['test']), np.asarray(acoustic['test']), np.asarray(bert_embs['test'])])\n",
    "predicted_test_labels = pred.argmax(axis=1)\n",
    "numeric_test_labels = np.array(label['test'])\n",
    "            \n",
    "eval_res = classification_report(numeric_test_labels, predicted_test_labels, \n",
    "                                    target_names = ['Neg', 'Pos', 'Neu'], \n",
    "                                    digits=4, output_dict=False)\n",
    "\n",
    "print(eval_res)\n",
    "\n",
    "cm = confusion_matrix(y_true=numeric_test_labels.tolist(), y_pred=predicted_test_labels.tolist())\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4947d7-8ee7-40d7-a7dc-aab84df22d09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
