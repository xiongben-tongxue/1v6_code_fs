{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f95c0ce-a9ea-4eeb-91a6-43637ac39686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 14:34:08.946056: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-12 14:34:09.030679: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-12 14:34:09.052155: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-12 14:34:09.429371: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-12 14:34:09.429411: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-12 14:34:09.429414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Bidirectional, Dense, Conv1D, LSTM, Flatten, Attention\n",
    "from utilz import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b29bdc72-f937-4ef3-bc1e-3f10ed1735f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 14:34:10.109115: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 14:34:10.137802: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-12 14:34:10.137913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6169bb24-9d5c-4180-9c02-68c70548fe39",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6af49354-ece8-454a-90f8-183ba1c9bf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "acoustic = load_features('./data/acoustic_wav2vec.pkl')\n",
    "# acoustic = load_features('./data/acoustic_opensml.pkl')\n",
    "label = load_features('./data/labels.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eb3fda-5b0e-4b65-9ba5-e2a14490d6c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36794564-fb8a-4078-bd70-b33a2d872962",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 19:54:33.121553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-03 19:54:33.146913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-03 19:54:33.147031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-03 19:54:33.147836: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-03 19:54:33.149764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-03 19:54:33.149869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-03 19:54:33.149937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-03 19:54:33.462406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-03 19:54:33.462552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-03 19:54:33.462630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-03 19:54:33.462701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13892 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 512)]        0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 64)               139520    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 139,715\n",
      "Trainable params: 139,715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = Input((128,512))\n",
    "h = Bidirectional(LSTM(32, dropout=0.3))(x)\n",
    "res = Dense(3, 'softmax')(h)\n",
    "    \n",
    "model = Model(inputs=x, outputs=res)\n",
    "model.compile(optimizer='Adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics='acc')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fe6f20b-4fac-4a48-b0c0-50cbf57dddd3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 1/86 [..............................] - ETA: 2:53 - loss: 1.4992 - acc: 0.1875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 19:54:48.317819: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8500\n",
      "2022-10-03 19:54:48.395922: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - ETA: 0s - loss: 1.0086 - acc: 0.5007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/A_model_BLSTM_wav2vec.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/A_model_BLSTM_wav2vec.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 9s 82ms/step - loss: 1.0086 - acc: 0.5007 - val_loss: 0.9889 - val_acc: 0.5395\n",
      "Epoch 2/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.9166 - acc: 0.5643 - val_loss: 0.9917 - val_acc: 0.5307\n",
      "Epoch 3/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.8547 - acc: 0.6053 - val_loss: 1.0426 - val_acc: 0.4715\n",
      "Epoch 4/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.8145 - acc: 0.6374 - val_loss: 0.9969 - val_acc: 0.5417\n",
      "Epoch 5/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.7498 - acc: 0.6827 - val_loss: 1.0337 - val_acc: 0.5307\n",
      "Epoch 6/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.6914 - acc: 0.7273 - val_loss: 1.0470 - val_acc: 0.5461\n",
      "Epoch 7/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.6231 - acc: 0.7617 - val_loss: 1.1012 - val_acc: 0.5417\n",
      "Epoch 8/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.5800 - acc: 0.7734 - val_loss: 1.0956 - val_acc: 0.4978\n",
      "Epoch 9/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.4909 - acc: 0.8392 - val_loss: 1.1553 - val_acc: 0.4693\n",
      "Epoch 10/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.4524 - acc: 0.8392 - val_loss: 1.2014 - val_acc: 0.4890\n",
      "Epoch 11/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.3974 - acc: 0.8655 - val_loss: 1.2280 - val_acc: 0.4539\n",
      "Epoch 12/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.3468 - acc: 0.8918 - val_loss: 1.3185 - val_acc: 0.5022\n",
      "Epoch 13/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.3081 - acc: 0.9086 - val_loss: 1.3398 - val_acc: 0.5044\n",
      "Epoch 14/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.2705 - acc: 0.9189 - val_loss: 1.3814 - val_acc: 0.4737\n",
      "Epoch 15/30\n",
      "86/86 [==============================] - 2s 18ms/step - loss: 0.2241 - acc: 0.9444 - val_loss: 1.5726 - val_acc: 0.5044\n",
      "Epoch 16/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.1977 - acc: 0.9430 - val_loss: 1.4731 - val_acc: 0.4759\n",
      "Epoch 17/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.1933 - acc: 0.9452 - val_loss: 1.4517 - val_acc: 0.4846\n",
      "Epoch 18/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.1705 - acc: 0.9554 - val_loss: 1.6152 - val_acc: 0.5000\n",
      "Epoch 19/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.1618 - acc: 0.9569 - val_loss: 1.5862 - val_acc: 0.4781\n",
      "Epoch 20/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.1395 - acc: 0.9664 - val_loss: 1.6319 - val_acc: 0.5000\n",
      "Epoch 21/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.1374 - acc: 0.9591 - val_loss: 1.6570 - val_acc: 0.5066\n",
      "Epoch 22/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.1423 - acc: 0.9627 - val_loss: 1.6561 - val_acc: 0.4715\n",
      "Epoch 23/30\n",
      "86/86 [==============================] - 2s 18ms/step - loss: 0.1024 - acc: 0.9803 - val_loss: 1.6241 - val_acc: 0.4934\n",
      "Epoch 24/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.0988 - acc: 0.9751 - val_loss: 1.7292 - val_acc: 0.4474\n",
      "Epoch 25/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.0838 - acc: 0.9868 - val_loss: 1.7290 - val_acc: 0.5044\n",
      "Epoch 26/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.1161 - acc: 0.9642 - val_loss: 1.7839 - val_acc: 0.4890\n",
      "Epoch 27/30\n",
      "86/86 [==============================] - 2s 18ms/step - loss: 0.0817 - acc: 0.9854 - val_loss: 1.9210 - val_acc: 0.4803\n",
      "Epoch 28/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.0771 - acc: 0.9832 - val_loss: 1.9236 - val_acc: 0.5000\n",
      "Epoch 29/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.0616 - acc: 0.9876 - val_loss: 1.9793 - val_acc: 0.4978\n",
      "Epoch 30/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.0557 - acc: 0.9876 - val_loss: 2.0861 - val_acc: 0.4912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe5afe409a0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_list = [ModelCheckpoint(filepath='./res/A_model_BLSTM_wav2vec.tf', monitor='val_loss', save_best_only=True, save_freq='epoch')]\n",
    "\n",
    "model.fit(x=np.asarray(acoustic['train']), y=np.asarray(label['train']), batch_size=16, epochs=30, \n",
    "            validation_data=[np.asarray(acoustic['valid']), np.asarray(label['valid'])],\n",
    "            callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "108fe31c-3e36-4de8-98d2-e7541ad3e80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg     0.5457    0.9395    0.6904       248\n",
      "         Pos     0.3846    0.0714    0.1205       140\n",
      "         Neu     0.2500    0.0145    0.0274        69\n",
      "\n",
      "    accuracy                         0.5339       457\n",
      "   macro avg     0.3934    0.3418    0.2794       457\n",
      "weighted avg     0.4517    0.5339    0.4157       457\n",
      "\n",
      "[[233  12   3]\n",
      " [130  10   0]\n",
      " [ 64   4   1]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./res/A_model_BLSTM_wav2vec.tf')\n",
    "pred = model.predict(np.asarray(acoustic['test']))\n",
    "predicted_test_labels = pred.argmax(axis=1)\n",
    "numeric_test_labels = np.array(label['test'])\n",
    "            \n",
    "eval_res = classification_report(numeric_test_labels, predicted_test_labels, \n",
    "                                    target_names = ['Neg', 'Pos', 'Neu'], \n",
    "                                    digits=4, output_dict=False)\n",
    "\n",
    "print(eval_res)\n",
    "\n",
    "cm = confusion_matrix(y_true=numeric_test_labels.tolist(), y_pred=predicted_test_labels.tolist())\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8c9fb8-abf5-4197-a006-cfba9e9e3b76",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58331c4f-3b45-4ce2-b6e8-803effb9d813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 128, 512)]        0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 63, 64)            98368     \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 64)               24832     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 123,395\n",
      "Trainable params: 123,395\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = Input((128,512))\n",
    "h = Conv1D(64, 3, 2)(x)\n",
    "h = Bidirectional(LSTM(32, dropout=0.3))(h)\n",
    "res = Dense(3, 'softmax')(h)\n",
    "    \n",
    "model = Model(inputs=x, outputs=res)\n",
    "model.compile(optimizer='Adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics='acc')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d3d18f9-dba7-48d8-a15c-a6591fdd2d30",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "83/86 [===========================>..] - ETA: 0s - loss: 0.9956 - acc: 0.5023"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn, lstm_cell_26_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/A_model_CNN-BLSTM_wav2vec.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/A_model_CNN-BLSTM_wav2vec.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 8s 78ms/step - loss: 0.9907 - acc: 0.5073 - val_loss: 0.9651 - val_acc: 0.5526\n",
      "Epoch 2/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.9459 - acc: 0.5497 - val_loss: 1.0127 - val_acc: 0.5022\n",
      "Epoch 3/30\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.9208 - acc: 0.5497 - val_loss: 0.9768 - val_acc: 0.5088\n",
      "Epoch 4/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.9052 - acc: 0.5629 - val_loss: 0.9661 - val_acc: 0.5329\n",
      "Epoch 5/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.8743 - acc: 0.5768 - val_loss: 0.9835 - val_acc: 0.5329\n",
      "Epoch 6/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.8258 - acc: 0.6294 - val_loss: 0.9864 - val_acc: 0.5395\n",
      "Epoch 7/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.7984 - acc: 0.6382 - val_loss: 0.9950 - val_acc: 0.5461\n",
      "Epoch 8/30\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.7524 - acc: 0.6762 - val_loss: 1.0029 - val_acc: 0.5417\n",
      "Epoch 9/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.7229 - acc: 0.6959 - val_loss: 1.0333 - val_acc: 0.5439\n",
      "Epoch 10/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.6835 - acc: 0.7032 - val_loss: 1.0550 - val_acc: 0.5263\n",
      "Epoch 11/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.6584 - acc: 0.7193 - val_loss: 1.1028 - val_acc: 0.5285\n",
      "Epoch 12/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.6252 - acc: 0.7398 - val_loss: 1.0627 - val_acc: 0.5241\n",
      "Epoch 13/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.5624 - acc: 0.7756 - val_loss: 1.1268 - val_acc: 0.5175\n",
      "Epoch 14/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.5180 - acc: 0.8048 - val_loss: 1.1207 - val_acc: 0.5285\n",
      "Epoch 15/30\n",
      "86/86 [==============================] - 1s 7ms/step - loss: 0.5151 - acc: 0.7836 - val_loss: 1.1664 - val_acc: 0.5614\n",
      "Epoch 16/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4761 - acc: 0.8129 - val_loss: 1.2298 - val_acc: 0.5022\n",
      "Epoch 17/30\n",
      "86/86 [==============================] - 1s 11ms/step - loss: 0.4364 - acc: 0.8282 - val_loss: 1.3036 - val_acc: 0.4934\n",
      "Epoch 18/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.4253 - acc: 0.8458 - val_loss: 1.3006 - val_acc: 0.4781\n",
      "Epoch 19/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3784 - acc: 0.8670 - val_loss: 1.3537 - val_acc: 0.5110\n",
      "Epoch 20/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3511 - acc: 0.8779 - val_loss: 1.3706 - val_acc: 0.5000\n",
      "Epoch 21/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3136 - acc: 0.8874 - val_loss: 1.5410 - val_acc: 0.5307\n",
      "Epoch 22/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.3065 - acc: 0.8940 - val_loss: 1.4882 - val_acc: 0.4890\n",
      "Epoch 23/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2860 - acc: 0.9057 - val_loss: 1.4045 - val_acc: 0.4956\n",
      "Epoch 24/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2590 - acc: 0.9145 - val_loss: 1.5118 - val_acc: 0.4978\n",
      "Epoch 25/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2750 - acc: 0.8984 - val_loss: 1.5725 - val_acc: 0.4825\n",
      "Epoch 26/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2007 - acc: 0.9401 - val_loss: 1.7418 - val_acc: 0.4934\n",
      "Epoch 27/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2313 - acc: 0.9196 - val_loss: 1.6028 - val_acc: 0.4759\n",
      "Epoch 28/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.2032 - acc: 0.9364 - val_loss: 1.6881 - val_acc: 0.4956\n",
      "Epoch 29/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1579 - acc: 0.9496 - val_loss: 1.7514 - val_acc: 0.4846\n",
      "Epoch 30/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.1493 - acc: 0.9554 - val_loss: 1.9450 - val_acc: 0.5197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe5007dd9f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_list = [ModelCheckpoint(filepath='./res/A_model_CNN-BLSTM_wav2vec.tf', monitor='val_loss', save_best_only=True, save_freq='epoch')]\n",
    "\n",
    "model.fit(x=np.asarray(acoustic['train']), y=np.asarray(label['train']), batch_size=16, epochs=30, \n",
    "            validation_data=[np.asarray(acoustic['valid']), np.asarray(label['valid'])],\n",
    "            callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5daba53a-4546-4492-8966-2364ba5a2fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg     0.5459    0.9839    0.7022       248\n",
      "         Pos     0.6667    0.0143    0.0280       140\n",
      "         Neu     0.1429    0.0145    0.0263        69\n",
      "\n",
      "    accuracy                         0.5405       457\n",
      "   macro avg     0.4518    0.3375    0.2521       457\n",
      "weighted avg     0.5220    0.5405    0.3936       457\n",
      "\n",
      "[[244   1   3]\n",
      " [135   2   3]\n",
      " [ 68   0   1]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./res/A_model_CNN-BLSTM_wav2vec.tf')\n",
    "\n",
    "pred = model.predict(np.asarray(acoustic['test']))\n",
    "predicted_test_labels = pred.argmax(axis=1)\n",
    "numeric_test_labels = np.array(label['test'])\n",
    "            \n",
    "eval_res = classification_report(numeric_test_labels, predicted_test_labels, \n",
    "                                    target_names = ['Neg', 'Pos', 'Neu'], \n",
    "                                    digits=4, output_dict=False)\n",
    "\n",
    "print(eval_res)\n",
    "\n",
    "cm = confusion_matrix(y_true=numeric_test_labels.tolist(), y_pred=predicted_test_labels.tolist())\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42be030-dcdb-4947-a14b-34774a87f464",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c368235f-abf3-4192-9bc3-cc8b85910252",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention_Self(tf.keras.layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super(Attention_Self, self).__init__(**kwargs)\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.S = tf.keras.layers.Dense(1)\n",
    "        self.units = units\n",
    "\n",
    "    def call(self, features):\n",
    "        # (64)\n",
    "        # attention matrix (64,64) \n",
    "        # attention matrix[0] 64 featrues2 time step scores\n",
    "        features_ = tf.expand_dims(features, 1)\n",
    "        score = tf.nn.tanh(self.W1(features) + self.W2(features_))\n",
    "        attention_weights = tf.nn.softmax(self.S(score), axis=1)\n",
    "        ATTN = attention_weights * (features)\n",
    "        ATTN = tf.reduce_sum(ATTN, axis=1)\n",
    "        \n",
    "        return ATTN\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(Attention_Self, self).get_config()\n",
    "        config.update({\"units\": self.units})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d54239a3-492a-40e1-9a16-613509c79a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 128, 512)]        0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 63, 64)            98368     \n",
      "                                                                 \n",
      " attention__self (Attention_  (None, 63, 64)           4193      \n",
      " Self)                                                           \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 64)               24832     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 127,588\n",
      "Trainable params: 127,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = Input((128,512))\n",
    "h = Conv1D(64, 3, 2)(x)\n",
    "h = Attention_Self(32)(h)\n",
    "h = Bidirectional(LSTM(32))(h)\n",
    "res = Dense(3, 'softmax')(h)\n",
    "    \n",
    "model = Model(inputs=x, outputs=res)\n",
    "model.compile(optimizer='Adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics='acc')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c28c7c4-1ac9-4527-8dc0-8df3ee6c72f5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "86/86 [==============================] - ETA: 0s - loss: 1.0106 - acc: 0.5329"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, dense_2_layer_call_fn, dense_2_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses while saving (showing 5 of 11). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/A_model_Att-BLSTM_wav2vec.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/A_model_Att-BLSTM_wav2vec.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 9s 85ms/step - loss: 1.0106 - acc: 0.5329 - val_loss: 0.9804 - val_acc: 0.5439\n",
      "Epoch 2/30\n",
      "83/86 [===========================>..] - ETA: 0s - loss: 0.9794 - acc: 0.5437"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, dense_2_layer_call_fn, dense_2_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses while saving (showing 5 of 11). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/A_model_Att-BLSTM_wav2vec.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/A_model_Att-BLSTM_wav2vec.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 7s 77ms/step - loss: 0.9813 - acc: 0.5409 - val_loss: 0.9776 - val_acc: 0.5461\n",
      "Epoch 3/30\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.9725 - acc: 0.5482"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, dense_2_layer_call_fn, dense_2_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses while saving (showing 5 of 11). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/A_model_Att-BLSTM_wav2vec.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/A_model_Att-BLSTM_wav2vec.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 7s 77ms/step - loss: 0.9725 - acc: 0.5482 - val_loss: 0.9753 - val_acc: 0.5482\n",
      "Epoch 4/30\n",
      "83/86 [===========================>..] - ETA: 0s - loss: 0.9645 - acc: 0.5520"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, dense_2_layer_call_fn, dense_2_layer_call_and_return_conditional_losses, dense_3_layer_call_fn, dense_3_layer_call_and_return_conditional_losses while saving (showing 5 of 11). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/A_model_Att-BLSTM_wav2vec.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/A_model_Att-BLSTM_wav2vec.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 7s 79ms/step - loss: 0.9643 - acc: 0.5512 - val_loss: 0.9700 - val_acc: 0.5395\n",
      "Epoch 5/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.9557 - acc: 0.5687 - val_loss: 0.9728 - val_acc: 0.5461\n",
      "Epoch 6/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.9512 - acc: 0.5658 - val_loss: 0.9826 - val_acc: 0.5263\n",
      "Epoch 7/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.9250 - acc: 0.6009 - val_loss: 0.9878 - val_acc: 0.5285\n",
      "Epoch 8/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.9198 - acc: 0.5972 - val_loss: 1.0016 - val_acc: 0.5395\n",
      "Epoch 9/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.9200 - acc: 0.5987 - val_loss: 0.9786 - val_acc: 0.5417\n",
      "Epoch 10/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.9094 - acc: 0.5980 - val_loss: 0.9961 - val_acc: 0.5417\n",
      "Epoch 11/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.9024 - acc: 0.6053 - val_loss: 0.9892 - val_acc: 0.5439\n",
      "Epoch 12/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.8710 - acc: 0.6330 - val_loss: 1.0198 - val_acc: 0.5373\n",
      "Epoch 13/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.8632 - acc: 0.6374 - val_loss: 1.0283 - val_acc: 0.5329\n",
      "Epoch 14/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.8696 - acc: 0.6287 - val_loss: 1.0351 - val_acc: 0.5241\n",
      "Epoch 15/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.8413 - acc: 0.6352 - val_loss: 1.0264 - val_acc: 0.5395\n",
      "Epoch 16/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.8205 - acc: 0.6528 - val_loss: 1.0767 - val_acc: 0.4978\n",
      "Epoch 17/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.8489 - acc: 0.6462 - val_loss: 1.0456 - val_acc: 0.5132\n",
      "Epoch 18/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.8167 - acc: 0.6601 - val_loss: 1.0587 - val_acc: 0.5285\n",
      "Epoch 19/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.8258 - acc: 0.6440 - val_loss: 1.0777 - val_acc: 0.5132\n",
      "Epoch 20/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.8007 - acc: 0.6564 - val_loss: 1.1078 - val_acc: 0.5175\n",
      "Epoch 21/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.8045 - acc: 0.6535 - val_loss: 1.0941 - val_acc: 0.5066\n",
      "Epoch 22/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.7893 - acc: 0.6689 - val_loss: 1.1086 - val_acc: 0.4868\n",
      "Epoch 23/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.7611 - acc: 0.6813 - val_loss: 1.1494 - val_acc: 0.5022\n",
      "Epoch 24/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.7415 - acc: 0.6879 - val_loss: 1.1155 - val_acc: 0.5022\n",
      "Epoch 25/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.7456 - acc: 0.6871 - val_loss: 1.1469 - val_acc: 0.5175\n",
      "Epoch 26/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.7394 - acc: 0.6893 - val_loss: 1.1129 - val_acc: 0.5307\n",
      "Epoch 27/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.6978 - acc: 0.7098 - val_loss: 1.1545 - val_acc: 0.5263\n",
      "Epoch 28/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.7186 - acc: 0.6901 - val_loss: 1.2133 - val_acc: 0.5022\n",
      "Epoch 29/30\n",
      "86/86 [==============================] - 1s 17ms/step - loss: 0.6826 - acc: 0.7083 - val_loss: 1.2529 - val_acc: 0.5022\n",
      "Epoch 30/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.6801 - acc: 0.7208 - val_loss: 1.2996 - val_acc: 0.4737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe55c35be50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_list = [ModelCheckpoint(filepath='./res/A_model_Att-BLSTM_wav2vec.tf', monitor='val_loss', save_best_only=True, save_freq='epoch')]\n",
    "\n",
    "model.fit(x=np.asarray(acoustic['train']), y=np.asarray(label['train']), batch_size=16, epochs=30, \n",
    "            validation_data=[np.asarray(acoustic['valid']), np.asarray(label['valid'])],\n",
    "            callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bc21663-1209-4b1c-8e89-342f9241154f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg     0.5518    0.9234    0.6908       248\n",
      "         Pos     0.4286    0.1286    0.1978       140\n",
      "         Neu     0.0000    0.0000    0.0000        69\n",
      "\n",
      "    accuracy                         0.5405       457\n",
      "   macro avg     0.3268    0.3507    0.2962       457\n",
      "weighted avg     0.4307    0.5405    0.4355       457\n",
      "\n",
      "[[229  19   0]\n",
      " [122  18   0]\n",
      " [ 64   5   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./res/A_model_Att-BLSTM_wav2vec.tf')\n",
    "\n",
    "pred = model.predict(np.asarray(acoustic['test']))\n",
    "predicted_test_labels = pred.argmax(axis=1)\n",
    "numeric_test_labels = np.array(label['test'])\n",
    "            \n",
    "eval_res = classification_report(numeric_test_labels, predicted_test_labels, \n",
    "                                    target_names = ['Neg', 'Pos', 'Neu'], \n",
    "                                    digits=4, output_dict=False)\n",
    "\n",
    "print(eval_res)\n",
    "\n",
    "cm = confusion_matrix(y_true=numeric_test_labels.tolist(), y_pred=predicted_test_labels.tolist())\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "301c3a58-dc88-44dd-a700-fbbab9ccb017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 128, 512)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 63, 64)       98368       ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " attention (Attention)          (None, 63, 64)       0           ['conv1d_2[0][0]',               \n",
      "                                                                  'conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirectional  (None, 64)          24832       ['attention[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 3)            195         ['bidirectional_3[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 123,395\n",
      "Trainable params: 123,395\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = Input((128,512))\n",
    "h = Conv1D(64, 3, 2)(x)\n",
    "qv_attention = Attention()([h, h])\n",
    "\n",
    "# q = GlobalAveragePooling1D()(q)\n",
    "# qv_attention = GlobalAveragePooling1D()(qv_attention)\n",
    "# h = Concatenate()([q, qv_attention])\n",
    "h = Bidirectional(LSTM(32))(qv_attention)\n",
    "res = Dense(3, 'softmax')(h)\n",
    "    \n",
    "model = Model(inputs=x, outputs=res)\n",
    "model.compile(optimizer='Adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics='acc')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a16a13ff-f290-432c-85f9-c7e3f4d60d8c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "85/86 [============================>.] - ETA: 0s - loss: 0.9860 - acc: 0.5294"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses, lstm_cell_20_layer_call_fn, lstm_cell_20_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/A_model_Att-BLSTM_wav2vec_v2.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/A_model_Att-BLSTM_wav2vec_v2.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 8s 78ms/step - loss: 0.9855 - acc: 0.5300 - val_loss: 0.9732 - val_acc: 0.5351\n",
      "Epoch 2/30\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.9384 - acc: 0.5541 - val_loss: 0.9882 - val_acc: 0.5439\n",
      "Epoch 3/30\n",
      "86/86 [==============================] - ETA: 0s - loss: 0.9292 - acc: 0.5629"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses, lstm_cell_20_layer_call_fn, lstm_cell_20_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/A_model_Att-BLSTM_wav2vec_v2.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/A_model_Att-BLSTM_wav2vec_v2.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 6s 72ms/step - loss: 0.9292 - acc: 0.5629 - val_loss: 0.9599 - val_acc: 0.5504\n",
      "Epoch 4/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.9421 - acc: 0.5461 - val_loss: 0.9746 - val_acc: 0.5219\n",
      "Epoch 5/30\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.9386 - acc: 0.5475 - val_loss: 0.9748 - val_acc: 0.5329\n",
      "Epoch 6/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.9245 - acc: 0.5461 - val_loss: 0.9649 - val_acc: 0.5570\n",
      "Epoch 7/30\n",
      "86/86 [==============================] - 1s 16ms/step - loss: 0.9074 - acc: 0.5504 - val_loss: 0.9903 - val_acc: 0.5395\n",
      "Epoch 8/30\n",
      "86/86 [==============================] - 1s 15ms/step - loss: 0.8952 - acc: 0.5607 - val_loss: 0.9887 - val_acc: 0.5197\n",
      "Epoch 9/30\n",
      "78/86 [==========================>...] - ETA: 0s - loss: 0.9265 - acc: 0.5449"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses, lstm_cell_20_layer_call_fn, lstm_cell_20_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/A_model_Att-BLSTM_wav2vec_v2.tf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./res/A_model_Att-BLSTM_wav2vec_v2.tf/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 6s 70ms/step - loss: 0.9307 - acc: 0.5461 - val_loss: 0.9504 - val_acc: 0.5636\n",
      "Epoch 10/30\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.8956 - acc: 0.5614 - val_loss: 0.9542 - val_acc: 0.5439\n",
      "Epoch 11/30\n",
      "86/86 [==============================] - 1s 8ms/step - loss: 0.9030 - acc: 0.5621 - val_loss: 0.9680 - val_acc: 0.5395\n",
      "Epoch 12/30\n",
      "86/86 [==============================] - 1s 10ms/step - loss: 0.8919 - acc: 0.5768 - val_loss: 0.9752 - val_acc: 0.5439\n",
      "Epoch 13/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.8754 - acc: 0.5797 - val_loss: 0.9842 - val_acc: 0.5351\n",
      "Epoch 14/30\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.8908 - acc: 0.5826 - val_loss: 0.9841 - val_acc: 0.5570\n",
      "Epoch 15/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.8797 - acc: 0.5673 - val_loss: 0.9795 - val_acc: 0.5482\n",
      "Epoch 16/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.8889 - acc: 0.5789 - val_loss: 0.9854 - val_acc: 0.5351\n",
      "Epoch 17/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.8931 - acc: 0.5789 - val_loss: 0.9914 - val_acc: 0.5351\n",
      "Epoch 18/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.8880 - acc: 0.5885 - val_loss: 1.0027 - val_acc: 0.5263\n",
      "Epoch 19/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.8939 - acc: 0.5651 - val_loss: 0.9804 - val_acc: 0.5351\n",
      "Epoch 20/30\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.9147 - acc: 0.5468 - val_loss: 1.0055 - val_acc: 0.4978\n",
      "Epoch 21/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.9099 - acc: 0.5614 - val_loss: 1.0164 - val_acc: 0.5044\n",
      "Epoch 22/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.9046 - acc: 0.5760 - val_loss: 1.0004 - val_acc: 0.5154\n",
      "Epoch 23/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.8801 - acc: 0.5877 - val_loss: 1.1100 - val_acc: 0.5351\n",
      "Epoch 24/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.8927 - acc: 0.5841 - val_loss: 1.0174 - val_acc: 0.5132\n",
      "Epoch 25/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.8722 - acc: 0.5892 - val_loss: 1.0069 - val_acc: 0.5395\n",
      "Epoch 26/30\n",
      "86/86 [==============================] - 1s 12ms/step - loss: 0.9010 - acc: 0.5826 - val_loss: 0.9880 - val_acc: 0.5197\n",
      "Epoch 27/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.8808 - acc: 0.5789 - val_loss: 0.9867 - val_acc: 0.5241\n",
      "Epoch 28/30\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.8692 - acc: 0.5958 - val_loss: 0.9980 - val_acc: 0.5132\n",
      "Epoch 29/30\n",
      "86/86 [==============================] - 1s 14ms/step - loss: 0.8527 - acc: 0.5972 - val_loss: 1.0021 - val_acc: 0.5307\n",
      "Epoch 30/30\n",
      "86/86 [==============================] - 1s 13ms/step - loss: 0.8191 - acc: 0.6279 - val_loss: 1.0042 - val_acc: 0.5110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe508535480>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_list = [ModelCheckpoint(filepath='./res/A_model_Att-BLSTM_wav2vec_v2.tf', monitor='val_loss', save_best_only=True, save_freq='epoch')]\n",
    "\n",
    "model.fit(x=np.asarray(acoustic['train']), y=np.asarray(label['train']), batch_size=16, epochs=30, \n",
    "            validation_data=[np.asarray(acoustic['valid']), np.asarray(label['valid'])],\n",
    "            callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bfc278d-65b5-44b7-ae7d-3b42c3ca5758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg     0.5572    0.9234    0.6950       248\n",
      "         Pos     0.3500    0.0500    0.0875       140\n",
      "         Neu     0.2308    0.0870    0.1263        69\n",
      "\n",
      "    accuracy                         0.5295       457\n",
      "   macro avg     0.3793    0.3534    0.3029       457\n",
      "weighted avg     0.4444    0.5295    0.4230       457\n",
      "\n",
      "[[229   7  12]\n",
      " [125   7   8]\n",
      " [ 57   6   6]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('./res/A_model_Att-BLSTM_wav2vec_v2.tf')\n",
    "\n",
    "pred = model.predict(np.asarray(acoustic['test']))\n",
    "predicted_test_labels = pred.argmax(axis=1)\n",
    "numeric_test_labels = np.array(label['test'])\n",
    "            \n",
    "eval_res = classification_report(numeric_test_labels, predicted_test_labels, \n",
    "                                    target_names = ['Neg', 'Pos', 'Neu'], \n",
    "                                    digits=4, output_dict=False)\n",
    "\n",
    "print(eval_res)\n",
    "\n",
    "cm = confusion_matrix(y_true=numeric_test_labels.tolist(), y_pred=predicted_test_labels.tolist())\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e919aa-cf9f-4583-ad3b-6f24d02b282f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
