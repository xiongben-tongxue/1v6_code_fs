{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eaa99ad-d3df-4c94-8729-9212d7cba4c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-19T03:55:27.094063400Z",
     "start_time": "2023-08-19T03:55:24.100565300Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import librosa \n",
    "import opensmile\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2Model, Wav2Vec2ForCTC\n",
    "from utilz import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16bac83c-219e-4558-b184-b0b8902a1241",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-19T03:55:30.035088500Z",
     "start_time": "2023-08-19T03:55:29.982744300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ae6a31-f1ee-47bb-9e9a-84deef03fdeb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# dataset = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n",
    "# dataset = dataset.sort(\"id\")\n",
    "# sampling_rate = dataset.features[\"audio\"].sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8181352c-e83d-4005-b691-01b1defa8e63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-19T03:55:38.986489900Z",
     "start_time": "2023-08-19T03:55:36.195819600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_9908\\1123121267.py:1: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load('C:/Test/0001.mp4', sr=16000) # ffmpeg\n",
      "C:\\ProgramData\\anaconda3\\envs\\myenv310\\lib\\site-packages\\librosa\\core\\audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    }
   ],
   "source": [
    "y, sr = librosa.load('C:/Test/0001.mp4', sr=16000) # ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30650ecb-4d31-40f8-b6ea-5bca45a494c8",
   "metadata": {},
   "source": [
    "# librosa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a34d544-379b-43e1-81ed-6650e9cd1345",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-19T03:58:58.597545600Z",
     "start_time": "2023-08-19T03:58:58.171765100Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'librosa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m mel_spec \u001B[38;5;241m=\u001B[39m \u001B[43mlibrosa\u001B[49m\u001B[38;5;241m.\u001B[39mfeature\u001B[38;5;241m.\u001B[39mmelspectrogram(y\u001B[38;5;241m=\u001B[39my,sr\u001B[38;5;241m=\u001B[39msr,n_mels\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m)\u001B[38;5;241m.\u001B[39mT\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(mel_spec\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;66;03m# 25ms\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'librosa' is not defined"
     ]
    }
   ],
   "source": [
    "mel_spec = librosa.feature.melspectrogram(y=y,sr=sr,n_mels=128).T\n",
    "print(mel_spec.shape) # 25ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373ee177-9ad0-46bb-98b9-33eed7417d1f",
   "metadata": {},
   "source": [
    "# Opensmile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "792138d1-ad82-4f33-b98d-b53b229dc011",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-19T04:15:30.834857700Z",
     "start_time": "2023-08-19T04:15:30.775861200Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'opensmile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m smile \u001B[38;5;241m=\u001B[39m \u001B[43mopensmile\u001B[49m\u001B[38;5;241m.\u001B[39mSmile(\n\u001B[0;32m      2\u001B[0m     feature_set\u001B[38;5;241m=\u001B[39mopensmile\u001B[38;5;241m.\u001B[39mFeatureSet\u001B[38;5;241m.\u001B[39mComParE_2016,\n\u001B[0;32m      3\u001B[0m     feature_level\u001B[38;5;241m=\u001B[39mopensmile\u001B[38;5;241m.\u001B[39mFeatureLevel\u001B[38;5;241m.\u001B[39mLowLevelDescriptors,\n\u001B[0;32m      4\u001B[0m )\n\u001B[0;32m      6\u001B[0m sml_fs \u001B[38;5;241m=\u001B[39m smile\u001B[38;5;241m.\u001B[39mprocess_file(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC:/Test/0001.mp4\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(sml_fs\u001B[38;5;241m.\u001B[39mshape)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'opensmile' is not defined"
     ]
    }
   ],
   "source": [
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "    feature_level=opensmile.FeatureLevel.LowLevelDescriptors,\n",
    ")\n",
    "\n",
    "sml_fs = smile.process_file('C:/Test/0001.mp4')\n",
    "print(sml_fs.shape)\n",
    "# 10ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa7d663-8b20-4129-be65-c5b52cb44881",
   "metadata": {},
   "source": [
    "# Wav2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "552215ed-ce03-4d9e-aeba-9c124699f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# English\n",
    "# MELD\n",
    "# processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "# model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d31891a6-6033-4ae0-9ce8-f07719b73b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/transformers/configuration_utils.py:364: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Chinese\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"ydshieh/wav2vec2-large-xlsr-53-chinese-zh-cn-gpt\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"ydshieh/wav2vec2-large-xlsr-53-chinese-zh-cn-gpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b31ddb14-26ac-4264-8774-c10a462bd7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 20:05:43.072207: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-03 20:05:43.170851: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-03 20:05:43.188666: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-03 20:05:43.575592: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-03 20:05:43.575640: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-03 20:05:43.575644: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 63, 512]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs = processor(dataset[0][\"audio\"][\"array\"], sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "\n",
    "inputs = processor(y, sampling_rate=sr, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    # outputs = model(**inputs) # for EN\n",
    "    outputs = model.wav2vec2(**inputs)\n",
    "    \n",
    "# last_hidden_states = outputs.last_hidden_state  # for EN\n",
    "last_hidden_states = outputs.extract_features # for CH\n",
    "list(last_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1e61aa-d6bf-4360-8004-f9d4dde0de06",
   "metadata": {},
   "source": [
    "# Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89faeb12-7551-4976-81e7-b1abe4c4dc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speech_feature(file, mode, max_len=128):\n",
    "    if mode == 'mel':\n",
    "        y, sr = librosa.load(file)\n",
    "        mel_spec = librosa.feature.melspectrogram(y, sr, n_mels=128).T # (time_steps, 128) (100,128)\n",
    "        if len(mel_spec)<max_len:\n",
    "            mel_spec = np.concatenate([mel_spec, np.zeros((max_len-len(mel_spec), 128))], axis=0)\n",
    "        return mel_spec[:max_len] #(128,128)\n",
    "    \n",
    "    elif mode == 'opensmile':\n",
    "        smile = opensmile.Smile(feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "                                feature_level=opensmile.FeatureLevel.LowLevelDescriptors)\n",
    "        sml_fs = smile.process_file(file)\n",
    "        if len(sml_fs)<max_len*2: \n",
    "            sml_fs = np.concatenate([sml_fs, np.zeros((max_len*2-len(sml_fs), 65))], axis=0)\n",
    "        return sml_fs[:max_len*2] #(256,65)\n",
    "    \n",
    "    elif mode == 'wav2vec':\n",
    "        y, sr = librosa.load(file, sr=16000)\n",
    "        inputs = processor(y, sampling_rate=sr, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model.wav2vec2(**inputs)\n",
    "        wav2vec_fs = outputs.extract_features[0].cpu().detach().numpy() # for CH\n",
    "        print(type(wav2vec_fs))\n",
    "        if len(wav2vec_fs)<max_len: \n",
    "            wav2vec_fs = np.concatenate([wav2vec_fs, np.zeros((max_len-len(wav2vec_fs), 512))], axis=0)\n",
    "        return wav2vec_fs[:max_len] #(128,512)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dbe7f1d-e2cc-42f6-9e89-6434a2c834d3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../SIMS/Raw/video_0001/0001.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0002.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0003.mp4 test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0004.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0005.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0006.mp4 test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0007.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0008.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0009.mp4 test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0010.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0011.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0012.mp4 valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0013.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0014.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0015.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0016.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0017.mp4 test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODE = 'wav2vec'\n",
    "\n",
    "video_path = '../SIMS/Raw/'\n",
    "video_ids, clip_ids, texts, annotations, modes = load_data('../SIMS/label.csv')\n",
    "\n",
    "acoustic = {'train':[], 'valid':[], 'test':[]}\n",
    "labels = {'train':[], 'valid':[], 'test':[]}\n",
    "label_dict = {'Negative':0, 'Positive':1, 'Neutral':2}\n",
    "    \n",
    "\n",
    "for video_id, clip_id, annotation, mode in zip(video_ids, clip_ids, annotations, modes):\n",
    "    clip_id_ = '000' + str(clip_id)\n",
    "    file_path = video_path + str(video_id) + '/' + clip_id_[-4:] + '.mp4' \n",
    "    \n",
    "    print(file_path, mode)    \n",
    "    \n",
    "    acoustic[mode].append(get_speech_feature(file_path, mode=MODE))\n",
    "    labels[mode].append(label_dict[annotation])\n",
    "    \n",
    "save_features(acoustic, './data/acoustic_wav2vec.pkl')\n",
    "save_features(labels, './data/labels.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c5f4eb-890e-4f6c-9f7c-4c71632c5dca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
