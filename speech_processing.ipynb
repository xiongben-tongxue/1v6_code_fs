{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eaa99ad-d3df-4c94-8729-9212d7cba4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import librosa \n",
    "import opensmile\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2Model, Wav2Vec2ForCTC\n",
    "from utilz import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16bac83c-219e-4558-b184-b0b8902a1241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ae6a31-f1ee-47bb-9e9a-84deef03fdeb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# dataset = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n",
    "# dataset = dataset.sort(\"id\")\n",
    "# sampling_rate = dataset.features[\"audio\"].sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8181352c-e83d-4005-b691-01b1defa8e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "y, sr = librosa.load('../SIMS/Raw/video_0001/0001.mp4', sr=16000) # ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30650ecb-4d31-40f8-b6ea-5bca45a494c8",
   "metadata": {},
   "source": [
    "# librosa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a34d544-379b-43e1-81ed-6650e9cd1345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17758/417018464.py:1: FutureWarning: Pass y=[ 0.          0.          0.         ... -0.04392989 -0.04456997\n",
      " -0.05147557], sr=16000 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  mel_spec = librosa.feature.melspectrogram(y,sr,n_mels=128).T\n"
     ]
    }
   ],
   "source": [
    "mel_spec = librosa.feature.melspectrogram(y,sr,n_mels=128).T\n",
    "print(mel_spec.shape) # 25ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373ee177-9ad0-46bb-98b9-33eed7417d1f",
   "metadata": {},
   "source": [
    "# Opensmile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "792138d1-ad82-4f33-b98d-b53b229dc011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SoX could not be found!\n",
      "\n",
      "    If you do not have SoX, proceed here:\n",
      "     - - - http://sox.sourceforge.net/ - - -\n",
      "\n",
      "    If you do (or think that you should) have SoX, double-check your\n",
      "    path variables.\n",
      "    \n",
      "/bin/sh: 1: sox: not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 65)\n"
     ]
    }
   ],
   "source": [
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "    feature_level=opensmile.FeatureLevel.LowLevelDescriptors,\n",
    ")\n",
    "\n",
    "sml_fs = smile.process_file('../SIMS/Raw/video_0001/0001.mp4')\n",
    "print(sml_fs.shape)\n",
    "# 10ms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa7d663-8b20-4129-be65-c5b52cb44881",
   "metadata": {},
   "source": [
    "# Wav2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "552215ed-ce03-4d9e-aeba-9c124699f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# English\n",
    "# MELD\n",
    "# processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "# model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d31891a6-6033-4ae0-9ce8-f07719b73b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/transformers/configuration_utils.py:364: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Chinese\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"ydshieh/wav2vec2-large-xlsr-53-chinese-zh-cn-gpt\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"ydshieh/wav2vec2-large-xlsr-53-chinese-zh-cn-gpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b31ddb14-26ac-4264-8774-c10a462bd7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 20:05:43.072207: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-03 20:05:43.170851: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-03 20:05:43.188666: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-03 20:05:43.575592: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-03 20:05:43.575640: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-03 20:05:43.575644: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 63, 512]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs = processor(dataset[0][\"audio\"][\"array\"], sampling_rate=sampling_rate, return_tensors=\"pt\")\n",
    "\n",
    "inputs = processor(y, sampling_rate=sr, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    # outputs = model(**inputs) # for EN\n",
    "    outputs = model.wav2vec2(**inputs)\n",
    "    \n",
    "# last_hidden_states = outputs.last_hidden_state  # for EN\n",
    "last_hidden_states = outputs.extract_features # for CH\n",
    "list(last_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1e61aa-d6bf-4360-8004-f9d4dde0de06",
   "metadata": {},
   "source": [
    "# Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89faeb12-7551-4976-81e7-b1abe4c4dc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speech_feature(file, mode, max_len=128):\n",
    "    if mode == 'mel':\n",
    "        y, sr = librosa.load(file)\n",
    "        mel_spec = librosa.feature.melspectrogram(y, sr, n_mels=128).T # (time_steps, 128) (100,128)\n",
    "        if len(word_embs)<max_len:\n",
    "            mel_spec = np.concatenate([mel_spec, np.zeros((max_len-len(mel_spec), 128))], axis=0)\n",
    "        return mel_spec[:max_len] #(128,128)\n",
    "    \n",
    "    elif mode == 'opensmile':\n",
    "        smile = opensmile.Smile(feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "                                feature_level=opensmile.FeatureLevel.LowLevelDescriptors)\n",
    "        sml_fs = smile.process_file(file)\n",
    "        if len(sml_fs)<max_len*2: \n",
    "            sml_fs = np.concatenate([sml_fs, np.zeros((max_len*2-len(sml_fs), 65))], axis=0)\n",
    "        return sml_fs[:max_len*2] #(256,65)\n",
    "    \n",
    "    elif mode == 'wav2vec':\n",
    "        y, sr = librosa.load(file, sr=16000)\n",
    "        inputs = processor(y, sampling_rate=sr, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model.wav2vec2(**inputs)\n",
    "        wav2vec_fs = outputs.extract_features[0].cpu().detach().numpy() # for CH\n",
    "        print(type(wav2vec_fs))\n",
    "        if len(wav2vec_fs)<max_len: \n",
    "            wav2vec_fs = np.concatenate([wav2vec_fs, np.zeros((max_len-len(wav2vec_fs), 512))], axis=0)\n",
    "        return wav2vec_fs[:max_len] #(128,512)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dbe7f1d-e2cc-42f6-9e89-6434a2c834d3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../SIMS/Raw/video_0001/0001.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0002.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0003.mp4 test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0004.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0005.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0006.mp4 test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0007.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0008.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0009.mp4 test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0010.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0011.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0012.mp4 valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0013.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0014.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0015.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0016.mp4 train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "../SIMS/Raw/video_0001/0017.mp4 test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chason/anaconda3/envs/deepeye/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  return f(*args, **kwargs)\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODE = 'wav2vec'\n",
    "\n",
    "video_path = '../SIMS/Raw/'\n",
    "video_ids, clip_ids, texts, annotations, modes = load_data('../SIMS/label.csv')\n",
    "\n",
    "acoustic = {'train':[], 'valid':[], 'test':[]}\n",
    "labels = {'train':[], 'valid':[], 'test':[]}\n",
    "label_dict = {'Negative':0, 'Positive':1, 'Neutral':2}\n",
    "    \n",
    "\n",
    "for video_id, clip_id, annotation, mode in zip(video_ids, clip_ids, annotations, modes):\n",
    "    clip_id_ = '000' + str(clip_id)\n",
    "    file_path = video_path + str(video_id) + '/' + clip_id_[-4:] + '.mp4' \n",
    "    \n",
    "    print(file_path, mode)    \n",
    "    \n",
    "    acoustic[mode].append(get_speech_feature(file_path, mode=MODE))\n",
    "    labels[mode].append(label_dict[annotation])\n",
    "    \n",
    "save_features(acoustic, './data/acoustic_wav2vec.pkl')\n",
    "save_features(labels, './data/labels.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c5f4eb-890e-4f6c-9f7c-4c71632c5dca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
